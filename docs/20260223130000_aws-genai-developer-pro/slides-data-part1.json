{
	"slides": [
		{
			"title": "AWS Certified Generative AI Developer - Professional",
			"content": [
				"試験対策スライド 全80枚",
				"2026年版 | 生成AI・Bedrock・RAG・エージェント・責任あるAI・LLMOps"
			],
			"layout": "center",
			"speakerNotes": "AWS Certified Generative AI Developer - Professional（ANA版）試験対策。7つのドメインを横断的にカバーします。"
		},
		{
			"title": "試験概要・ドメイン構成",
			"content": ["![w:900 center](assets/slide02-exam-overview.svg)"],
			"layout": "default",
			"speakerNotes": "7ドメイン構成。Bedrockの比重が最も高く、次いでRAGとプロンプトエンジニアリング。生成AI基礎は広く薄く出題される傾向。"
		},
		{
			"title": "アジェンダ (1/2)",
			"content": [
				"**Domain 1**: 生成AI基礎 — LLM・Transformer・FM・推論パラメータ",
				"**Domain 2**: Amazon Bedrock — API・Knowledge Bases・Agents・Guardrails",
				"**Domain 3**: RAG & ベクターDB — チャンキング・エンベディング・Advanced RAG",
				"**Domain 4**: プロンプトエンジニアリング — CoT・ReAct・Few-shot・インジェクション対策"
			],
			"layout": "default",
			"speakerNotes": "前半4ドメインのアジェンダ。"
		},
		{
			"title": "アジェンダ (2/2)",
			"content": [
				"**Domain 5**: AIエージェント — Bedrock Agents・マルチエージェント・Function Calling",
				"**Domain 6**: 責任あるAI & セキュリティ — バイアス・Guardrails・ガバナンス",
				"**Domain 7**: MLOps / LLMOps — SageMaker・デプロイ戦略・モデル監視",
				"**まとめ**: 試験頻出ポイント & 重要AWSサービス一覧"
			],
			"layout": "default",
			"speakerNotes": "後半3ドメイン＋まとめ。"
		},
		{
			"title": "生成AIとは？従来のAIとの違い",
			"content": ["![w:900 center](assets/slide05-genai-vs-traditional.svg)"],
			"layout": "default",
			"speakerNotes": "従来AIは識別・分類・予測（入力→ラベル）。生成AIは新しいコンテンツを生成（入力→新しいデータ）。基盤となる技術は深層学習だが、スケールと目的が大きく異なる。試験では「生成AIとdiscriminative AIの違い」が出題される。"
		},
		{
			"title": "機械学習→深層学習→生成AIの進化",
			"content": ["![w:900 center](assets/slide06-ai-evolution.svg)"],
			"layout": "default",
			"speakerNotes": "1950年代の記号AIから現代の生成AIまでの進化。2017年のTransformer論文「Attention Is All You Need」が転換点。GPT-3（2020）、ChatGPT（2022）、Claude（2023）と急速に発展。試験ではこの歴史的文脈より技術的な差異が重要。"
		},
		{
			"title": "大規模言語モデル（LLM）の仕組み",
			"content": ["![w:900 center](assets/slide07-llm-mechanism.svg)"],
			"layout": "default",
			"speakerNotes": "LLMはトークン列の確率分布をモデル化。次のトークンを予測するタスク（次トークン予測）で事前学習。パラメータ数が多いほど（数十億〜数兆）表現力が高い。試験では「事前学習」「ファインチューニング」「RLHF」の違いが重要。"
		},
		{
			"title": "トークン化とトークン数",
			"content": [
				"![w:900 center](assets/slide08-tokenization.svg)",
				"1 token ≈ 英語0.75単語 / 日本語1〜2文字 | コスト計算の基本単位"
			],
			"layout": "default",
			"speakerNotes": "BPE（Byte Pair Encoding）やSentencePieceなどのサブワードトークナイザーを使用。トークン数はコストと速度に直結。AWS Bedrockではin/outトークンで課金。日本語は英語の約1.5〜2倍のトークン数になる傾向。"
		},
		{
			"title": "エンベディングとベクター表現",
			"content": ["![w:900 center](assets/slide09-embeddings.svg)"],
			"layout": "default",
			"speakerNotes": "単語・文・ドキュメントを高次元ベクター（768〜4096次元）に変換。意味的に近いテキストはベクター空間で近くに配置される。RAGの基盤技術。Amazon Titan Embeddingsが代表的なAWSのエンベディングモデル。コサイン類似度で類似度計算。"
		},
		{
			"title": "Transformer アーキテクチャ概要",
			"content": ["![w:900 center](assets/slide10-transformer.svg)"],
			"layout": "default",
			"speakerNotes": "2017年Google「Attention Is All You Need」で提案。Encoder-Decoder構造（翻訳）、Encoder Only（BERT系、分類・埋め込み）、Decoder Only（GPT系、テキスト生成）の3タイプ。LLMはほぼDecoder Only。Multi-Head Self-Attentionが核心。"
		},
		{
			"title": "アテンションメカニズム",
			"content": ["![w:900 center](assets/slide11-attention.svg)"],
			"layout": "default",
			"speakerNotes": "Attention(Q,K,V) = softmax(QK^T / √d_k)V。Q=Query（現在のトークン）、K=Key（他のトークン）、V=Value（情報）。Multi-Headでは複数の視点（head）で同時に注意を計算。長距離依存関係の捕捉が得意。"
		},
		{
			"title": "Foundation Models の種類と用途",
			"content": ["![w:900 center](assets/slide12-fm-types.svg)"],
			"layout": "default",
			"speakerNotes": "テキスト生成（Claude・Llama）、画像生成（Stability AI・Titan Image）、コード生成（CodeWhisperer・Claude）、エンベディング（Titan Embeddings）、マルチモーダル（Claude 3・Nova）。試験ではユースケースに応じたFM選択が頻出。"
		},
		{
			"title": "マルチモーダルモデル",
			"content": ["![w:900 center](assets/slide13-multimodal.svg)"],
			"layout": "default",
			"speakerNotes": "複数のモダリティ（テキスト・画像・音声・動画）を統合処理。Claude 3 Sonnet/Opus、Amazon Nova Pro/Liteがマルチモーダル対応。Vision機能でPDF・スクリーンショットの解析も可能。BedrockのConverseAPIでマルチモーダルリクエストを統一的に扱える。"
		},
		{
			"title": "推論パラメータ（温度・Top-P・Top-K・MaxTokens）",
			"content": ["![w:900 center](assets/slide14-inference-params.svg)"],
			"layout": "default",
			"speakerNotes": "Temperature: 0=決定論的、1=創造的。Top-P: 累積確率でサンプリング（nucleus sampling）。Top-K: 上位K個のトークンからサンプリング。MaxTokens: 生成する最大トークン数。試験では各パラメータの効果と適切な設定値が問われる。"
		},
		{
			"title": "コンテキストウィンドウとその影響",
			"content": ["![w:900 center](assets/slide15-context-window.svg)"],
			"layout": "default",
			"speakerNotes": "コンテキストウィンドウ = モデルが一度に処理できるトークン数の上限。Claude 3.5: 200K、Llama 3: 128K、Titan Text: 32K。ウィンドウを超えると古い情報が「忘れられる」。長文書処理やマルチターン会話設計に重要。コスト増加にも直結。"
		},
		{
			"title": "ハルシネーション：原因と対策",
			"content": ["![w:900 center](assets/slide16-hallucination.svg)"],
			"layout": "default",
			"speakerNotes": "ハルシネーション = LLMが事実と異なる情報を自信を持って生成する現象。原因: 学習データのバイアス・知識の欠如・確率的生成。対策: RAGで根拠情報を注入、Guardrailsで不正確情報をフィルタリング、グラウンディング（引用明示）、温度を下げる。試験で最頻出の課題。"
		},
		{
			"title": "モデル評価指標（BLEU・ROUGE・BERTScore）",
			"content": ["![w:900 center](assets/slide17-eval-metrics.svg)"],
			"layout": "default",
			"speakerNotes": "BLEU: 機械翻訳評価、n-gramの一致率。ROUGE: 要約評価、再現率重視。BERTScore: 意味的類似度（コサイン類似度）。Perplexity: 言語モデルの予測精度。人間評価（Human Eval）も重要。Bedrock Model EvaluationはLLM-as-a-judgeも対応。"
		},
		{
			"title": "生成AIのユースケース分類",
			"content": ["![w:900 center](assets/slide18-use-cases.svg)"],
			"layout": "default",
			"speakerNotes": "テキスト生成（コンテンツ作成・要約・翻訳）、コード生成（CodeWhisperer・デバッグ）、会話AI（カスタマーサポート・チャットボット）、検索拡張（RAG）、画像生成（マーケティング）、データ分析（自然言語でのDB照会）。試験ではユースケースに最適なAWSサービスの選択が重要。"
		},
		{
			"title": "Amazon Bedrock 概要",
			"content": ["![w:900 center](assets/slide19-bedrock-overview.svg)"],
			"layout": "default",
			"speakerNotes": "Amazon Bedrockはマネージド型FMサービス。APIを通じて複数プロバイダーのFMにアクセス可能。サーバーレス、データはAWSインフラに留まる（プライバシー保証）。主な機能: InvokeModel/Converse API、Knowledge Bases、Agents、Guardrails、Flows、Model Evaluation、Fine-tuning。"
		},
		{
			"title": "Bedrock で利用できる FM プロバイダー",
			"content": ["![w:900 center](assets/slide20-fm-providers.svg)"],
			"layout": "default",
			"speakerNotes": "Anthropic Claude（テキスト・マルチモーダル）、Amazon Titan（テキスト・エンベディング・画像）、Amazon Nova（最新世代）、Meta Llama（オープンソース系）、Stability AI（画像生成）、Mistral AI、AI21 Labs Jurassic。試験ではプロバイダーとモデル特性の理解が重要。"
		},
		{
			"title": "Bedrock API: InvokeModel / Converse",
			"content": [
				"**InvokeModel API**: モデル固有のリクエスト形式、単一ターン向け",
				"**Converse API**: 統一インターフェース、マルチターン対話、ツール利用対応"
			],
			"code": "import boto3, json\n\nbr = boto3.client('bedrock-runtime', region_name='us-east-1')\n\n# Converse API（推奨：統一インターフェース）\nresponse = br.converse(\n    modelId='anthropic.claude-3-5-sonnet-20241022-v2:0',\n    messages=[{\n        'role': 'user',\n        'content': [{'text': 'AWSのBedrockを説明してください'}]\n    }],\n    inferenceConfig={\n        'maxTokens': 1024,\n        'temperature': 0.7,\n        'topP': 0.9\n    }\n)\nprint(response['output']['message']['content'][0]['text'])",
			"codeLanguage": "python",
			"layout": "default",
			"speakerNotes": "Converse APIはモデル間の差異を吸収する統一API。マルチターン会話、ツール使用（Function Calling）をサポート。InvokeModelはモデル固有の形式が必要だが、より細かい制御が可能。試験では両APIの使い分けが問われる。"
		},
		{
			"title": "Knowledge Bases for Bedrock",
			"content": ["![w:900 center](assets/slide22-knowledge-bases.svg)"],
			"layout": "default",
			"speakerNotes": "Knowledge Bases = マネージド型RAGサービス。S3のドキュメントを自動でチャンキング・エンベディング・ベクターDB格納。対応ベクターDB: OpenSearch Serverless、Pinecone、Redis Enterprise、MongoDB Atlas。RetrieveAndGenerate APIで検索〜生成を一括実行。メタデータフィルタリング対応。"
		},
		{
			"title": "Bedrock Agents: 概要と仕組み",
			"content": ["![w:900 center](assets/slide23-bedrock-agents.svg)"],
			"layout": "default",
			"speakerNotes": "Bedrock Agentsは自律的にタスクを実行するAIエージェント。ReActパターン（推論→行動→観察のループ）を実装。アクショングループ（Lambda/OpenAPI）でツールを定義。Knowledge Basesと連携でRAGも統合可能。マルチエージェント機能でサブエージェントを呼び出せる。オーケストレーター戦略はReAct/Chain-of-Thought。"
		},
		{
			"title": "Bedrock Agents: アクショングループ",
			"content": [
				"アクショングループ = エージェントが実行できるアクションのセット",
				"**実装方法**: OpenAPI スキーマ（Lambda連携）または組み込みアクション"
			],
			"code": "# OpenAPI スキーマ例（アクショングループ定義）\n{\n  \"openapi\": \"3.0.0\",\n  \"paths\": {\n    \"/getWeather\": {\n      \"get\": {\n        \"description\": \"指定した都市の天気を取得\",\n        \"parameters\": [{\n          \"name\": \"city\",\n          \"in\": \"query\",\n          \"required\": true,\n          \"schema\": {\"type\": \"string\"}\n        }],\n        \"responses\": {\n          \"200\": {\"description\": \"天気情報\"}\n        }\n      }\n    }\n  }\n}",
			"codeLanguage": "json",
			"layout": "default",
			"speakerNotes": "アクショングループはLambda関数をバックエンドにしてOpenAPIスキーマで定義するか、Amazon Bedrockの組み込みアクション（ユーザー入力の確認、KB検索）を使う。エージェントは自動的に適切なアクションを選択して実行。"
		},
		{
			"title": "Bedrock Guardrails",
			"content": ["![w:900 center](assets/slide25-guardrails.svg)"],
			"layout": "default",
			"speakerNotes": "Guardrailsは有害コンテンツ・機密情報の入出力フィルタリング機能。コンテンツフィルター（ヘイトスピーチ・暴力）、PIIマスキング（メール・クレカ番号）、トピック拒否（特定トピックをブロック）、グラウンディングチェック（ハルシネーション検出）、ワードフィルター。全Bedrockモデルに適用可能。"
		},
		{
			"title": "Bedrock Flows",
			"content": ["![w:900 center](assets/slide26-bedrock-flows.svg)"],
			"layout": "default",
			"speakerNotes": "Bedrock Flowsはノーコード/ローコードでAIワークフローを構築するビジュアルビルダー。ノードタイプ: 入力・FM・Knowledge Base・Lambda・条件分岐・ループ・出力。複雑なマルチステップのAIパイプラインをGUIで構築。プロンプトチェーニングやRAGパイプラインの構築に有効。"
		},
		{
			"title": "Bedrock Model Evaluation",
			"content": ["![w:900 center](assets/slide27-model-evaluation.svg)"],
			"layout": "default",
			"speakerNotes": "2種類の評価: 自動評価（ROUGE・BERTScore等の指標）とLLM-as-a-judge（別のLLMが評価）。評価タスク: テキスト要約・QA・テキスト分類・オープンエンド生成。モデル比較やファインチューニング後の品質確認に使用。Human Evaluationジョブ機能で人間レビューも統合可能。"
		},
		{
			"title": "Fine-tuning vs Continued Pre-training",
			"content": ["![w:900 center](assets/slide28-finetuning-vs-cpt.svg)"],
			"layout": "default",
			"speakerNotes": "Fine-tuning: ラベル付きデータ（プロンプト→回答ペア）でタスク特化。特定の形式・トーン・ドメインに適応。Continued Pre-training (CPT): ラベルなし大量テキストで追加学習。ドメイン知識の注入（医療・法律・社内文書）。どちらもBedrockのマネージド機能として提供。コストと効果のトレードオフを試験では問われる。"
		},
		{
			"title": "Bedrock カスタムモデルのワークフロー",
			"content": ["![w:900 center](assets/slide29-custom-model-workflow.svg)"],
			"layout": "default",
			"speakerNotes": "S3にトレーニングデータ準備→Bedrockカスタマイズジョブ作成→学習実行→カスタムモデル保存→プロビジョンドスループット購入→推論実行。Fine-tuningはClaudeのInstruct系、Titanが対応。CPTはTitan Text系が対応。カスタムモデルはマーケットプレイスで共有も可能。"
		},
		{
			"title": "Amazon Titan シリーズ",
			"content": ["![w:900 center](assets/slide30-titan-series.svg)"],
			"layout": "default",
			"speakerNotes": "Titan Text: テキスト生成・対話（G1 Lite/Express）。Titan Text Premier: 高性能テキスト生成。Titan Embeddings: テキストエンベディング（V2: 1536次元）。Titan Multimodal Embeddings: 画像+テキストの複合エンベディング。Titan Image Generator: 高品質画像生成。すべてAWSネイティブのFM。"
		}
	]
}
