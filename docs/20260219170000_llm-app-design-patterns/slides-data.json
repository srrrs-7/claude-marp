{
	"slides": [
		{
			"title": "LLMアプリ設計パターン完全ガイド",
			"content": [
				"RAG・Fine-tuning・Agents・評価フレームワーク",
				"アーキテクト・テックリード向け実践ガイド",
				"2026年版"
			],
			"layout": "center"
		},
		{
			"title": "アジェンダ（1/2）",
			"content": [
				"**Section 1:** LLMアプリの基礎と技術選定",
				"**Section 2:** プロンプトエンジニアリング",
				"**Section 3:** RAG設計パターン（16スライド）",
				"**Section 4:** Fine-tuning（13スライド）",
				"**Section 5:** AIエージェント設計（17スライド）"
			],
			"layout": "default"
		},
		{
			"title": "アジェンダ（2/2）",
			"content": [
				"**Section 6:** 評価フレームワーク（12スライド）",
				"**Section 7:** プロダクション設計パターン（14スライド）",
				"**Section 8:** 設計選択ガイド・まとめ（8スライド）",
				"---",
				"全100スライド・所要時間：約60分"
			],
			"layout": "default"
		},
		{
			"title": "LLMアプリ開発の現在地",
			"content": [
				"**なぜ設計パターンが必要か**",
				"LLMは強力だが「万能ツール」ではない — 使い方を間違えると高コスト・低品質・セキュリティリスク",
				"**3つの現実的課題**",
				"① ハルシネーション — 事実と異なる回答を自信を持って返す",
				"② 知識カットオフ — 最新情報・内部データにアクセスできない",
				"③ コスト爆発 — 非効率な実装は月数十万円のAPI費用に",
				"**本ガイドのゴール**",
				"「どのパターンをいつ使うか」の意思決定フレームワークを提供"
			],
			"layout": "default"
		},
		{
			"title": "Section 1: LLMアプリの基礎",
			"content": ["技術選定・アーキテクチャ・トレードオフ"],
			"layout": "section"
		},
		{
			"title": "LLMの仕組みと限界",
			"content": [
				"**LLMの本質**: 次のトークンを確率的に予測するニューラルネットワーク",
				"**強み**",
				"自然言語理解・生成、コード生成、推論、要約、翻訳",
				"**根本的な限界**",
				"ハルシネーション（確率的生成のため「それらしい嘘」を生成）",
				"知識カットオフ（学習データの日付で知識が固定）",
				"コンテキスト制限（入力長に上限 — GPT-4o: 128K、Claude 3.5: 200K）",
				"決定論的でない（同じ入力でも毎回異なる出力）",
				"内部状態なし（ステートレス — セッション間で記憶を保持しない）"
			],
			"layout": "default"
		},
		{
			"title": "4つの主要アプローチ概観",
			"content": [
				"**① プロンプトエンジニアリング** — モデルを変えずに指示を工夫",
				"適用場面: ほぼすべてのタスク。最初に試すべきアプローチ",
				"**② RAG（検索拡張生成）** — 外部知識をリアルタイムで注入",
				"適用場面: 最新情報・社内文書・大規模知識ベース",
				"**③ Fine-tuning** — モデルの重みを特定タスク向けに更新",
				"適用場面: 特定スタイル・ドメイン特化・プロンプトでは達成困難な品質",
				"**④ AIエージェント** — ツールを使い複数ステップで自律実行",
				"適用場面: 複雑な推論・外部API連携・繰り返し作業の自動化"
			],
			"layout": "default"
		},
		{
			"title": "アーキテクチャの共通コンポーネント",
			"content": [
				"**入力層**: ユーザー入力の受付・バリデーション・サニタイズ",
				"**プロンプト構築層**: テンプレート管理・コンテキスト注入・Few-shot例",
				"**LLM呼び出し層**: モデル選択・パラメータ管理・リトライ・フォールバック",
				"**後処理層**: 出力パース・バリデーション・フィルタリング",
				"**観測可能性層**: ログ・トレース・コスト追跡・評価メトリクス",
				"**キャッシュ層**: セマンティックキャッシュ・レスポンスキャッシュ"
			],
			"layout": "default"
		},
		{
			"title": "コスト・レイテンシ・品質のトレードオフ",
			"content": [
				"**プロンプトエンジニアリング**: コスト○ レイテンシ○ 品質△（上限あり）",
				"**RAG**: コスト△（ベクターDB費用追加） レイテンシ△（検索時間） 品質○",
				"**Fine-tuning**: コスト✗（学習費用高） レイテンシ○（小モデル可） 品質◎",
				"**エージェント**: コスト✗（多回呼び出し） レイテンシ✗（秒〜分） 品質◎",
				"---",
				"**鉄則**: 複雑なアプローチを先に採用しない",
				"Prompt → RAG → Fine-tuning → Agents の順で評価"
			],
			"layout": "default"
		},
		{
			"title": "技術選定フレームワーク",
			"content": [
				"**Step 1: プロンプトエンジニアリングで解けるか？**",
				"→ Few-shot / CoT / システムプロンプトで80%の品質が出るなら採用",
				"**Step 2: 最新情報・社内データが必要か？**",
				"→ Yes → RAG を検討",
				"**Step 3: 特定のスタイル・形式・ドメイン知識が必要か？**",
				"→ プロンプトで達成困難 → Fine-tuning を検討",
				"**Step 4: 複数ステップの推論・外部ツール実行が必要か？**",
				"→ Yes → エージェントを検討",
				"**Step 5: 複数のアプローチの組み合わせ**",
				"→ RAG + Fine-tuning、RAG + エージェント など組み合わせも有効"
			],
			"layout": "default"
		},
		{
			"title": "ベースモデル選択（2026年版）",
			"content": [
				"**クローズドモデル（API）**",
				"GPT-4o — OpenAI。コーディング・推論に強み。Function Calling成熟",
				"Claude 3.5 Sonnet — Anthropic。長文コンテキスト・安全性。コードに優秀",
				"Gemini 1.5 Pro — Google。1Mコンテキスト。マルチモーダル強み",
				"**オープンモデル（セルフホスト）**",
				"Llama 3.1 70B — Meta。商用利用可。高品質でコスト効率良",
				"Mistral Large — 欧州産。多言語・コーディング。Apache 2.0",
				"Qwen 2.5 72B — Alibaba。日本語・中国語に強み",
				"**選択基準**: データ主権、コスト上限、レイテンシ要件、言語サポート"
			],
			"layout": "default"
		},
		{
			"title": "プロダクション要件チェックリスト",
			"content": [
				"**機能要件**",
				"□ 精度・品質の定義（どのメトリクスで何%以上か）",
				"□ レイテンシ要件（P50/P95/P99）",
				"□ スループット要件（同時リクエスト数）",
				"**非機能要件**",
				"□ コスト上限（月間APIコスト予算）",
				"□ データ主権・プライバシー規制（GDPR等）",
				"□ 可用性要件（SLA）",
				"□ セキュリティ要件（データの機密分類）",
				"□ 観測可能性（ログ・トレース・アラート）"
			],
			"layout": "default"
		},
		{
			"title": "Section 2: プロンプトエンジニアリング",
			"content": ["設計の基礎 — すべてのアプローチの土台"],
			"layout": "section"
		},
		{
			"title": "プロンプトエンジニアリングの基礎",
			"content": [
				"**構造化プロンプトの4要素**",
				"① **Role（役割）**: 「あなたはシニアソフトウェアエンジニアです」",
				"② **Task（タスク）**: 明確で具体的な指示。動詞で始める",
				"③ **Context（文脈）**: 背景情報・制約・対象者",
				"④ **Format（形式）**: 出力形式の明示（JSON、箇条書き、N文字以内）",
				"**効果的なプロンプトの原則**",
				"具体的であること（「良い文章を書いて」→「技術ブログ記事を500字で」）",
				"例を示すこと（Few-shot）",
				"段階的思考を促すこと（CoT）"
			],
			"layout": "default"
		},
		{
			"title": "CoT・ToT・GoTパターン",
			"content": [
				"**Chain-of-Thought（CoT）**",
				"「ステップバイステップで考えてください」で推論精度が大幅向上",
				"数学・論理・コード生成に特に有効",
				"**Tree-of-Thought（ToT）**",
				"複数の推論パスを探索し最良を選択",
				"複雑な問題解決・計画立案に有効。コスト↑",
				"**Graph-of-Thought（GoT）**",
				"推論を有向グラフで表現。関係性の複雑なタスクに適合",
				"**Self-Consistency**",
				"同じ質問を複数回実行し多数決。精度↑コスト↑"
			],
			"layout": "default"
		},
		{
			"title": "Few-shot / Zero-shot 戦略",
			"content": [
				"**Zero-shot**: 例なしで直接指示",
				"「以下のレビューを Positive/Negative/Neutral に分類してください」",
				"→ シンプルなタスクに有効。プロンプトが短い",
				"**One-shot**: 例を1つ提示",
				"→ 出力形式の統一に有効",
				"**Few-shot**: 例を3〜8個提示",
				"→ 複雑なタスク・ドメイン特化に有効",
				"**選択ガイド**",
				"まずZero-shotで試す → 品質不足 → Few-shot追加",
				"例の品質が結果に直結（悪い例はむしろ有害）",
				"例は多様性を確保（同じパターンの繰り返し不可）"
			],
			"layout": "default"
		},
		{
			"title": "システムプロンプト設計",
			"content": [
				"**システムプロンプトの役割**",
				"モデルの「人格・役割・制約」を定義。ユーザー入力より優先度高",
				"**設計パターン**",
				"① ペルソナ定義: 「あなたは〇〇社の製品サポートエキスパートです」",
				"② 制約明示: 「製品以外のトピックには応じないでください」",
				"③ 出力フォーマット指定: 「必ずJSON形式で返答してください」",
				"④ 安全ガードレール: 「有害・違法なコンテンツを生成しないでください」",
				"**ベストプラクティス**",
				"短く明確に（長すぎると重要指示が埋もれる）",
				"バージョン管理必須（Git + プロンプトレジストリ）",
				"プロンプトインジェクション対策を組み込む"
			],
			"layout": "default"
		},
		{
			"title": "プロンプトテンプレート管理",
			"content": [
				"**なぜプロンプトのバージョン管理が必要か**",
				"プロンプト変更がモデル更新と同等の本番影響を持つ",
				"A/Bテストなしの変更は品質劣化リスク",
				"**管理方法**",
				"① Git管理: プロンプトをコードと同様にコミット",
				"② プロンプトレジストリ: LangSmith / Promptfoo / 独自DB",
				"③ セマンティックバージョニング: v1.2.3 形式",
				"**デプロイ戦略**",
				"カナリアリリース（5%のトラフィックで新プロンプトを検証）",
				"フィーチャーフラグによる即時ロールバック機能"
			],
			"layout": "default"
		},
		{
			"title": "構造化出力（JSON mode・Function Calling）",
			"content": ["LLMの出力を型安全に扱う手法"]
		},
		{
			"title": "構造化出力（JSON mode・Function Calling）（コード例）",
			"content": [],
			"code": "# OpenAI JSON mode + Pydantic\nfrom pydantic import BaseModel\nfrom openai import OpenAI\n\nclass ProductReview(BaseModel):\n    sentiment: Literal[\"positive\", \"negative\", \"neutral\"]\n    score: float  # 0.0 - 1.0\n    key_points: list[str]\n\nclient = OpenAI()\nresponse = client.beta.chat.completions.parse(\n    model=\"gpt-4o\",\n    messages=[{\"role\": \"user\", \"content\": f\"レビュー分析: {review_text}\"}],\n    response_format=ProductReview,  # 型安全な出力\n)\nresult = response.choices[0].message.parsed\nprint(result.sentiment, result.score)",
			"codeLanguage": "python"
		},
		{
			"title": "プロンプトエンジニアリングの限界",
			"content": [
				"**プロンプトだけでは解決できない問題**",
				"① 知識の鮮度 — 学習データ以降の情報は取得不可 → RAGが必要",
				"② 大規模知識ベース — コンテキスト長を超える文書群 → RAGが必要",
				"③ 一貫したスタイル — 大量のFew-shotは非効率 → Fine-tuningが必要",
				"④ 複数ステップの外部操作 — DB更新・API呼び出し → エージェントが必要",
				"⑤ ドメイン専門用語 — 特殊な語彙・フォーマット → Fine-tuningが必要",
				"**次のステップ**: 上記に当てはまる場合、他のアプローチを検討"
			],
			"layout": "default"
		},
		{
			"title": "Section 3: RAG設計パターン",
			"content": ["Retrieval-Augmented Generation — 検索拡張生成"],
			"layout": "section"
		},
		{
			"title": "RAGアーキテクチャ（Naive RAG）",
			"content": [
				"**RAGの基本フロー**",
				"① Indexing: 文書 → チャンキング → Embedding → ベクターDB保存",
				"② Retrieval: クエリ → Embedding → 類似度検索 → Top-K文書取得",
				"③ Generation: クエリ + 取得文書 → プロンプト構築 → LLM生成",
				"**RAGが解決する問題**",
				"知識カットオフ → 常に最新文書を参照",
				"ハルシネーション低減 → 根拠となるソースを提供",
				"大規模知識ベース → 文書全体をコンテキストに入れる必要なし",
				"**Naive RAGの課題**",
				"低品質なチャンキング、検索精度の限界、長文への対応困難"
			],
			"layout": "default"
		},
		{
			"title": "Embedding + Vector DBの仕組み",
			"content": [
				"**Embeddingとは**",
				"テキストを意味を保ったまま数値ベクトル（例: 1536次元）に変換",
				"意味的に近いテキストは高次元空間で近い位置に配置",
				"**類似度検索**",
				"コサイン類似度 / ドット積 / ユークリッド距離",
				"k-NN（完全探索）vs ANN（近似最近傍）— HNSW, IVF-PQ",
				"**インデックス構造**",
				"HNSW（Hierarchical Navigable Small World）: 高速・高精度。メモリ大",
				"IVF-PQ: メモリ効率良。精度トレードオフあり",
				"**次元数の注意点**",
				"次元数↑ = 精度↑ コスト↑ 次元の呪いに注意"
			],
			"layout": "default"
		},
		{
			"title": "チャンキング戦略",
			"content": [
				"**Fixed-size Chunking**",
				"固定文字数（例: 512トークン）でオーバーラップ付き分割",
				"実装簡単。意味の分断リスクあり",
				"**Semantic Chunking**",
				"意味の境界（段落・文章の転換点）で分割",
				"品質↑ 実装複雑↑",
				"**Hierarchical Chunking（Parent-Child）**",
				"大きなチャンク（Summary）と小さなチャンク（Detail）を二重インデックス",
				"検索は小チャンク → 提供は大チャンク",
				"**Sentence-Window Chunking**",
				"文単位でインデックス → 周辺N文をコンテキストとして提供",
				"**推奨**: まずFixed-size（512/128 overlap）から始め、品質不足で改善"
			],
			"layout": "default"
		},
		{
			"title": "Embeddingモデル比較",
			"content": [
				"**OpenAI text-embedding-3-large**",
				"次元: 3072（削減可能）、MTEB 64.6、コスト: $0.13/1M tokens",
				"バランス良。OpenAI API利用中なら第一選択",
				"**Cohere embed-v3**",
				"多言語対応（100言語）、Reranking APIが優秀",
				"**BGE-M3（BAAI、オープン）**",
				"多言語・マルチ機能（Dense+Sparse+ColBERT）、セルフホスト可",
				"**E5-mistral-7b（オープン）**",
				"LLMベースEmbedding。高品質。推論コスト高",
				"**日本語特化**",
				"ruri-large（cl-nagoya）: 日本語MTEBでトップクラス"
			],
			"layout": "default"
		},
		{
			"title": "ベクターDB比較",
			"content": [
				"**Pinecone** — フルマネージド。スケール簡単。コスト高。ベンダーロック",
				"**Weaviate** — OSS+マネージド。GraphQLクエリ。マルチモーダル対応",
				"**Qdrant** — OSS。Rust製で高速。フィルタリング強力。セルフホスト最有力",
				"**pgvector（PostgreSQL拡張）** — 既存PGインフラ活用。スケール限界あり",
				"**ChromaDB** — 開発・プロトタイプ向け。ローカル起動が容易",
				"**Milvus** — 大規模（10億ベクター）対応。Zilliz Cloud版あり",
				"---",
				"**選択基準**: 既存インフラ → pgvector / 新規フルマネージド → Pinecone / セルフホスト本番 → Qdrant"
			],
			"layout": "default"
		},
		{
			"title": "高度な検索技術",
			"content": [
				"**HyDE（Hypothetical Document Embeddings）**",
				"クエリ → LLMで仮想的な回答文を生成 → その文をEmbeddingして検索",
				"短いクエリの検索精度が大幅改善。レイテンシ・コスト増",
				"**Reranking**",
				"初回検索（Top-50）→ 再順序付け（Cross-encoder）→ Top-5を採用",
				"Cohere Rerank / BGE-Reranker が高精度",
				"**MMR（Maximal Marginal Relevance）**",
				"関連性と多様性のバランスを保った検索結果を返す",
				"類似した文書の重複取得を防ぐ",
				"**Self-Query Retrieval**",
				"LLMがクエリを解析し、メタデータフィルター付き検索クエリを生成"
			],
			"layout": "default"
		},
		{
			"title": "Hybrid Search（Dense + Sparse）",
			"content": [
				"**Dense Search（ベクター検索）の弱点**",
				"新語・固有名詞・専門用語に弱い（学習データにない単語）",
				"例: 「AWS re:Invent 2025」「GPT-5o」などの新用語",
				"**Sparse Search（BM25キーワード検索）**",
				"TF-IDFベースの古典的全文検索。新語・固有名詞に強い",
				"意味的類似性を考慮しない",
				"**Hybrid Searchの仕組み**",
				"Dense スコア + Sparse スコア を RRF（Reciprocal Rank Fusion）で統合",
				"実装: Qdrant Hybrid / Weaviate Hybrid / Elasticsearch ELSER",
				"**推奨構成**",
				"プロダクションでは Hybrid Search をデフォルトに設定"
			],
			"layout": "default"
		},
		{
			"title": "Advanced RAGアーキテクチャ",
			"content": [
				"**Modular RAG（モジュラーRAG）**",
				"Pre-Retrieval → Retrieval → Post-Retrieval → Generation の各段階を独立モジュール化",
				"**Pre-Retrieval改善**",
				"クエリ書き換え（Query Rewriting）",
				"クエリ分解（Sub-question Decomposition）",
				"HyDE",
				"**Post-Retrieval改善**",
				"Reranking（再順位付け）",
				"コンテキスト圧縮（LLMLingua — 重要部分のみ抽出）",
				"**Agentic RAG**",
				"RAGをエージェントのツールとして使用。必要に応じて反復検索"
			],
			"layout": "default"
		},
		{
			"title": "GraphRAG",
			"content": [
				"**GraphRAGとは**",
				"文書をチャンクではなく「知識グラフ（エンティティと関係）」として表現",
				"Microsoft Research が2024年に発表",
				"**通常RAGとの違い**",
				"通常RAG: 局所的な類似チャンクを検索",
				"GraphRAG: エンティティ間の関係・コミュニティサマリーを活用",
				"**強み**",
				"「全体像を要約して」などのグローバルクエリに強い",
				"複数文書にまたがる関係の推論が可能",
				"**弱み・注意点**",
				"インデックス構築コストが高い（GPT-4を大量使用）",
				"小規模文書セットには過剰",
				"適用場面: 研究論文・法律文書・複雑な技術文書"
			],
			"layout": "default"
		},
		{
			"title": "マルチモーダルRAG",
			"content": [
				"**マルチモーダルRAGとは**",
				"テキスト・画像・表・PDFの混合文書を統合的に検索・活用",
				"**実装アプローチ**",
				"① テキスト抽出: OCR（Tesseract/AWS Textract）でテキスト化してRAG",
				"② キャプション生成: LLMで画像/表をテキスト説明に変換してインデックス",
				"③ マルチベクター: テキスト・画像それぞれをEmbeddingして別々にインデックス",
				"**ColPali（推奨）**",
				"PDF/スキャン文書のページ全体をVision Embeddingで直接インデックス",
				"OCR不要。レイアウト情報を保持",
				"**ユースケース**",
				"技術マニュアル（図解含む）、財務報告書（表含む）、スライドセット"
			],
			"layout": "default"
		},
		{
			"title": "RAGパイプライン実装",
			"content": ["LlamaIndexを使ったシンプルなRAGパイプライン"]
		},
		{
			"title": "RAGパイプライン実装（コード例）",
			"content": [],
			"code": "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\nfrom llama_index.core.node_parser import SentenceWindowNodeParser\nfrom llama_index.embeddings.openai import OpenAIEmbedding\nfrom llama_index.llms.openai import OpenAI\n\n# 文書読み込み + Sentence-Window チャンキング\ndocuments = SimpleDirectoryReader(\"./docs\").load_data()\nnode_parser = SentenceWindowNodeParser.from_defaults(\n    window_size=3,  # 前後3文をコンテキストとして付与\n    window_metadata_key=\"window\",\n)\n# インデックス構築（Embedding + ベクターDB）\nindex = VectorStoreIndex.from_documents(\n    documents,\n    transformations=[node_parser],\n    embed_model=OpenAIEmbedding(model=\"text-embedding-3-large\"),\n)\n# クエリエンジン（Reranking付き）\nquery_engine = index.as_query_engine(\n    similarity_top_k=10,   # まず10件取得\n    node_postprocessors=[CohereRerank(top_n=3)],  # 3件に絞る\n)\nresponse = query_engine.query(\"LLMの評価指標は？\")\nprint(response)",
			"codeLanguage": "python"
		},
		{
			"title": "RAG評価指標（RAGAS）",
			"content": [
				"**RAGAS（RAG Assessment）の4指標**",
				"① **Faithfulness（忠実性）**: 回答が取得文書の内容に基づいているか",
				"ハルシネーション検出の主要指標。高いほど良い（目標: 0.8以上）",
				"② **Answer Relevancy（回答関連性）**: 回答がクエリに関連しているか",
				"③ **Context Precision（文脈精度）**: 取得文書にどれだけ関連コンテキストが含まれるか",
				"④ **Context Recall（文脈再現率）**: 正解に必要なコンテキストをどれだけ取得できたか",
				"**実装**",
				"from ragas import evaluate → 自動評価パイプライン",
				"LLM-as-a-Judgeを活用（GPT-4oで各指標を評価）"
			],
			"layout": "default"
		},
		{
			"title": "RAGのデバッグ・改善ループ",
			"content": [
				"**問題診断フロー**",
				"品質が低い → Faithfulness低い？ → 検索は合ってるが生成が失敗 → プロンプト改善",
				"品質が低い → Context Recall低い？ → 必要な文書が取得できていない → チャンキング/検索改善",
				"**よくある原因と対策**",
				"チャンクサイズが大きすぎる → サイズを128〜256に縮小",
				"Embeddingモデルが不適切 → ドメイン特化モデルへ変更",
				"検索上位K件が少ない → Top-Kを増やしてRerankで絞る",
				"クエリが短い → HyDEで拡張",
				"**デバッグツール**: LangSmith / Arize Phoenix でトレース可視化"
			],
			"layout": "default"
		},
		{
			"title": "RAGアンチパターン",
			"content": [
				"❌ **チャンクサイズを考えずに固定**: 文書タイプによって最適サイズが異なる",
				"❌ **Top-K=3で固定**: クエリの複雑さに応じて動的に変更すべき",
				"❌ **Embeddingモデルを変えずにデータ再利用**: モデル変更時はインデックス再構築必須",
				"❌ **検索結果を評価しない**: Retrievalの品質を単体でモニタリングすべき",
				"❌ **全文書を同じ優先度で扱う**: ドキュメントの信頼性・鮮度に重み付けを",
				"❌ **メタデータフィルターを使わない**: 日付・部門・バージョンでフィルタリングが効果的",
				"❌ **RAGだけで機密情報管理**: アクセス制御（ABAC）を必ずRAGに組み込む"
			],
			"layout": "default"
		},
		{
			"title": "RAG いつ使うべきか",
			"content": [
				"**RAGが適している場面**",
				"✅ 最新情報が必要（ニュース・製品情報・法規制）",
				"✅ 社内文書・ナレッジベースへの質問応答",
				"✅ 根拠・ソースの提示が必要なユースケース",
				"✅ 数百〜数百万文書の大規模知識ベース",
				"✅ 知識が頻繁に更新される（再インデックスのみで対応可）",
				"**RAGが不適切な場面**",
				"❌ 特定のスタイル・口調・形式の習得（→ Fine-tuning）",
				"❌ ドメイン専門用語の解釈（→ Fine-tuning）",
				"❌ 文書が存在しない純粋な推論タスク（→ プロンプト）",
				"❌ リアルタイム行動が必要（→ エージェント）"
			],
			"layout": "default"
		},
		{
			"title": "Section 4: Fine-tuning",
			"content": ["モデルの重みを更新してドメイン適応"],
			"layout": "section"
		},
		{
			"title": "Fine-tuningとは・なぜ必要か",
			"content": [
				"**Fine-tuningの定義**",
				"事前学習済みモデルの重みを、特定タスクのデータで追加学習すること",
				"**RAGでは解決できない問題**",
				"① 特定のトーン・スタイルの習得（企業ブランドボイス）",
				"② ドメイン専門用語の正確な解釈（医療・法律・金融）",
				"③ 特定のフォーマットへの一貫した出力",
				"④ 推論時にコンテキストを注入せずに知識を内包させたい",
				"**Fine-tuningの効果**",
				"小型モデル（7B）でGPT-4レベルの特定タスク精度を実現可能",
				"推論コスト削減（大型モデルから小型特化モデルへ）",
				"レイテンシ改善"
			],
			"layout": "default"
		},
		{
			"title": "Fine-tuningの種類",
			"content": [
				"**Full Fine-tuning**",
				"全パラメータを更新。最高精度。GPU要件が高く費用大",
				"GPT-3 175B → A100 80GB × 8台 × 数日",
				"**LoRA（Low-Rank Adaptation）**",
				"重みの変分を低ランク行列で近似。パラメータの1〜10%のみ更新",
				"A100 × 1台で7Bモデルをファインチューニング可能",
				"**QLoRA（Quantized LoRA）**",
				"4bit量子化 + LoRA。VRAM使用量をさらに削減",
				"24GB GPU（RTX 3090）で13Bモデルが可能",
				"**Adapter Tuning**",
				"モデルのレイヤー間に小さなアダプタ層を追加。モデル本体は凍結",
				"**推奨**: ほぼ全ての用途でQLoRAから始める"
			],
			"layout": "default"
		},
		{
			"title": "LoRA詳解",
			"content": [
				"**LoRAの数学的仕組み**",
				"通常の重み更新: W → W + ΔW（ΔWは同じサイズ）",
				"LoRA: ΔW ≈ A × B（低ランク行列の積で近似）",
				"A: (d × r)、B: (r × k)、r << d,k（典型的なr=4〜64）",
				"**パラメータ削減例（LLama-2 7B、r=8）**",
				"Full Fine-tuning: 7B パラメータ更新",
				"LoRA: 約8M パラメータのみ更新（約0.1%）",
				"**ハイパーパラメータ**",
				"rank（r）: 低いほど高速・省メモリ。高いほど表現力↑",
				"alpha（スケーリング係数）: 通常はrの2倍が出発点",
				"target_modules: attention層（q_proj, v_proj）が基本"
			],
			"layout": "default"
		},
		{
			"title": "データセット設計",
			"content": [
				"**データ量の目安（Instruction Tuning）**",
				"最小: 100〜500サンプル（特定タスクの形式学習）",
				"推奨: 1,000〜10,000サンプル（品質のある多様なデータ）",
				"大規模: 100K+ サンプル（RLHF・汎用ファインチューニング）",
				"**データ品質が最重要**",
				"1,000件の高品質データ > 10,000件の低品質データ",
				"**フォーマット（Instruction Following形式）**",
				"{\"instruction\": \"〇〇してください\", \"input\": \"入力データ\", \"output\": \"期待される出力\"}",
				"**データソース**",
				"社内ログ・既存QA・専門家によるアノテーション・合成データ（GPT-4で生成）",
				"**注意点**: テストデータは必ず分離（汚染防止）"
			],
			"layout": "default"
		},
		{
			"title": "Instruction Tuning vs RLHF vs DPO",
			"content": [
				"**Instruction Tuning（SFT）**",
				"高品質なInstruction-Responseペアで教師あり学習",
				"最もシンプル。データ準備が鍵",
				"**RLHF（人間のフィードバックからの強化学習）**",
				"人間の選好データ → Reward Model学習 → PPOで最適化",
				"GPT-4・Claude・Llamaで採用。コスト・実装複雑度が高い",
				"**DPO（Direct Preference Optimization）**",
				"RLHFの簡略版。選好ペア（chosen/rejected）で直接最適化",
				"Reward Modelが不要。RLHFと同等の品質でシンプル",
				"→ **現在の主流**: SFT → DPO の2段階が標準的",
				"**ORPO / SimPO**: DPOの後継。参照モデル不要でさらにシンプル"
			],
			"layout": "default"
		},
		{
			"title": "Fine-tuning実装（QLoRA）",
			"content": ["Hugging Face TRL + QLoRAによる実装例"]
		},
		{
			"title": "Fine-tuning実装（QLoRA）（コード例）",
			"content": [],
			"code": "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\nfrom peft import LoraConfig, get_peft_model\nfrom trl import SFTTrainer, SFTConfig\n\n# 4bit量子化でモデルをロード\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16,\n)\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"meta-llama/Llama-3.1-8B\",\n    quantization_config=bnb_config,\n)\n# LoRA設定\nlora_config = LoraConfig(\n    r=16, lora_alpha=32,\n    target_modules=[\"q_proj\", \"v_proj\"],\n    lora_dropout=0.05,\n)\nmodel = get_peft_model(model, lora_config)\n# 学習\ntrainer = SFTTrainer(\n    model=model,\n    train_dataset=dataset,\n    args=SFTConfig(output_dir=\"./output\", num_train_epochs=3),\n)\ntrainer.train()",
			"codeLanguage": "python"
		},
		{
			"title": "モデル評価と過学習の検出",
			"content": [
				"**評価セットの重要性**",
				"学習データとは独立した評価セット（20%程度）を必ず用意",
				"**過学習のサイン**",
				"Train Loss↓ / Eval Loss↑ の乖離が広がる",
				"学習データと同じ表現しか生成しなくなる",
				"**過学習の対策**",
				"Early Stopping（Eval Lossが改善しなくなったら学習停止）",
				"Weight Decay（正則化）",
				"Dropout（LoRAのlora_dropout）",
				"データ拡張",
				"**評価メトリクス**",
				"生成タスク: ROUGE / BLEU / BERTScore",
				"分類タスク: Accuracy / F1",
				"ドメイン特化: LLM-as-a-Judge でカスタム評価"
			],
			"layout": "default"
		},
		{
			"title": "量子化・最適化",
			"content": [
				"**なぜ量子化するか**",
				"モデルサイズ・VRAM削減、推論速度向上",
				"**量子化手法比較**",
				"FP16（16bit）: 精度高。標準的。7B = 14GB VRAM",
				"GPTQ（4bit/8bit）: 高精度量子化。GPU推論向け",
				"AWQ（4bit）: 活性化を考慮した量子化。GPTQより高精度",
				"GGUF（旧GGML）: CPU/GPU混合推論。llama.cpp対応",
				"**VRAM早見表（7Bモデル）**",
				"FP16: 14GB / INT8: 7GB / INT4: 4GB",
				"**プロダクション推奨**",
				"GPU専有: AWQ 4bit / CPU含む: GGUF Q4_K_M"
			],
			"layout": "default"
		},
		{
			"title": "プロダクション展開",
			"content": [
				"**vLLM（推奨・GPU）**",
				"PagedAttentionによる高スループット推論サーバー",
				"OpenAI互換API。バッチ処理で最大スループット最大化",
				"Llama 3.1 8B: A100 1枚で〜2000 tokens/sec",
				"**TGI（Text Generation Inference）**",
				"Hugging Face製。Kubernetes対応。マネージドクラウドあり",
				"**Ollama**",
				"ローカル・開発環境向け。GGUF形式を簡単実行",
				"**クラウドマネージド**",
				"AWS SageMaker JumpStart / Bedrock Custom Model",
				"Google Vertex AI Fine-tuning",
				"**コスト考慮事項**",
				"専用GPU vs サーバーレス推論（AWS Lambda + GGUF）"
			],
			"layout": "default"
		},
		{
			"title": "Fine-tuningコスト計算",
			"content": [
				"**学習コスト（A100 80GB）**",
				"Llama-3.1 8B QLoRA（10K samples, 3 epoch）: 〜$5〜20",
				"Llama-3.1 70B QLoRA（10K samples）: 〜$50〜200",
				"**クラウドサービス比較**",
				"OpenAI Fine-tuning（GPT-3.5）: $8/1M training tokens",
				"AWS Bedrock（Titan）: $0.008/1K training tokens",
				"Modal.com / RunPod: $2〜4/h（A100）",
				"**推論コスト比較**",
				"GPT-4o: $5/1M input tokens",
				"Fine-tuned Llama-3.1 8B (vLLM): 〜$0.1/1M tokens（自社GPU）",
				"**ROI計算**: 月間1B tokens → GPT-4o: $5000 / Llama-tuned: $100"
			],
			"layout": "default"
		},
		{
			"title": "RAG vs Fine-tuning の選択基準",
			"content": [
				"**RAGを選ぶ場合**",
				"✅ 知識が頻繁に更新される（週次・日次）",
				"✅ 情報のソース・根拠を提示する必要がある",
				"✅ 大規模文書コーパス（100K+ ページ）",
				"✅ プロトタイプを素早く作りたい",
				"**Fine-tuningを選ぶ場合**",
				"✅ 特定スタイル・トーン・フォーマットの一貫性",
				"✅ ドメイン専門用語・略語の正確な解釈",
				"✅ 知識が比較的静的（月次更新以下）",
				"✅ 推論コストを長期的に削減したい",
				"**両方使う（推奨パターン）**",
				"Fine-tuned モデル + RAG = 最高品質",
				"例: カスタマイズされた医療モデル + 最新ガイドライン検索"
			],
			"layout": "default"
		},
		{
			"title": "Fine-tuningアンチパターン",
			"content": [
				"❌ **プロンプトで解決できる問題をFine-tuning**: まずプロンプト改善を試みる",
				"❌ **少量・低品質データでのFine-tuning**: 100件の粗悪データは有害",
				"❌ **評価データなしのFine-tuning**: ベースラインとの比較なしでは効果測定不可",
				"❌ **知識注入目的のFine-tuning**: 知識は RAG で注入、Fine-tuningは挙動変更用",
				"❌ **過学習を無視**: Eval Lossを監視せずにエポック数を増やし続ける",
				"❌ **Fine-tuning後に元モデルを廃棄**: LoRAアダプタのみ保存し元モデルは再利用",
				"❌ **セキュリティ考慮なし**: 訓練データにPII・機密情報が含まれていないか確認必須"
			],
			"layout": "default"
		},
		{
			"title": "Section 5: AIエージェント設計",
			"content": ["自律的推論とツール実行による複雑タスクの解決"],
			"layout": "section"
		},
		{
			"title": "AIエージェントとは・コアコンセプト",
			"content": [
				"**AIエージェントの定義**",
				"目標を達成するために、ツールを使いながら複数ステップを自律的に実行するLLMシステム",
				"**エージェントの4つのコアコンポーネント**",
				"① **LLM（Brain）**: 推論・計画・意思決定の中枢",
				"② **Tools（Hands）**: 外部API・DB・コード実行・Web検索など",
				"③ **Memory（Memory）**: 短期（コンテキスト）+ 長期（外部ストレージ）",
				"④ **Planner（Planning）**: タスク分解・実行順序の決定",
				"**エージェントが必要な場面**",
				"単一のLLM呼び出しでは解決できない複雑なマルチステップタスク",
				"外部システム（DB・API・ファイルシステム）との連携が必要なタスク"
			],
			"layout": "default"
		},
		{
			"title": "ReActパターン詳解",
			"content": [
				"**ReAct（Reasoning + Acting）**",
				"思考（Thought）→ 行動（Action）→ 観察（Observation）のループ",
				"Yao et al., 2023 が提唱。最も広く使われるエージェントパターン",
				"**実行フロー例**（「東京の天気は？」）",
				"Thought: 天気情報が必要。天気APIを呼ぶべきか",
				"Action: weather_tool(location='Tokyo')",
				"Observation: {'temp': 12, 'condition': 'Cloudy'}",
				"Thought: 取得できた。回答を生成できる",
				"Answer: 東京は12度で曇りです",
				"**強み**: 推論過程が透明。デバッグしやすい",
				"**弱み**: ステップ数に比例してコスト・レイテンシが増加"
			],
			"layout": "default"
		},
		{
			"title": "Plan-and-Executeパターン",
			"content": [
				"**Plan-and-Executeとは**",
				"最初に全体計画を立て、各ステップを順次実行するパターン",
				"ReActとの違い: 事前に計画を立ててからアクション",
				"**フロー**",
				"① Planner LLM: タスクをN個のサブタスクに分解",
				"② Executor: 各サブタスクをツールで実行",
				"③ Replanner: 実行結果を見て計画を動的に修正",
				"**適用場面**",
				"長期的・複雑なタスク（レポート作成・コードリファクタリング）",
				"事前に全体像を把握する必要があるタスク",
				"**LangGraph実装**: StateGraph + Plan node + Execute node"
			],
			"layout": "default"
		},
		{
			"title": "Reflexionパターン",
			"content": [
				"**Reflexionとは**",
				"実行結果を振り返り、自己評価・改善を繰り返すパターン",
				"Shinn et al., 2023 が提唱",
				"**フロー**",
				"① タスク実行（ReActベース）",
				"② Evaluator: 結果が目標を達成したか判定",
				"③ Reflector: 失敗原因の言語化（反省文の生成）",
				"④ 反省を踏まえて再実行",
				"**強み**",
				"初回失敗からの回復能力。品質↑",
				"コーディングタスク・推論問題で特に有効",
				"**弱み**",
				"反省ループが無限に続く可能性（最大試行回数の設定が必須）"
			],
			"layout": "default"
		},
		{
			"title": "Tool use / Function Calling設計",
			"content": [
				"**Function Callingとは**",
				"LLMが自然言語の意図を解析し、適切な関数を選択・引数を生成する機能",
				"OpenAI / Anthropic / Gemini が標準でサポート",
				"**ツール定義の原則**",
				"① 単一責任: 1ツール = 1機能。複数の機能を詰め込まない",
				"② 明確な説明: ツールの目的・引数・戻り値を明確に記述",
				"③ エラー処理: ツールは必ずエラー状態を返せるよう設計",
				"④ 冪等性: 同じ引数での複数回実行が安全",
				"**ツールカテゴリ**",
				"読み取り専用（検索・取得）/ 副作用あり（書き込み・送信・実行）",
				"副作用ありツールは承認フローを組み込む"
			],
			"layout": "default"
		},
		{
			"title": "ツール設計のベストプラクティス",
			"content": ["Claude / OpenAI Function Callingのツール定義例"]
		},
		{
			"title": "ツール設計のベストプラクティス（コード例）",
			"content": [],
			"code": "# Anthropic Tool use 定義\ntools = [\n    {\n        \"name\": \"search_documents\",\n        \"description\": \"社内ナレッジベースから関連文書を検索します。\"\n                       \"最新の製品仕様・手順書・FAQの検索に使用してください。\",\n        \"input_schema\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": {\n                    \"type\": \"string\",\n                    \"description\": \"検索クエリ。自然言語で記述\"\n                },\n                \"top_k\": {\n                    \"type\": \"integer\",\n                    \"description\": \"取得する文書数（1-10）\",\n                    \"default\": 5\n                }\n            },\n            \"required\": [\"query\"]\n        }\n    }\n]\n# エージェント呼び出し\nresponse = client.messages.create(\n    model=\"claude-sonnet-4-6\",\n    tools=tools,\n    messages=[{\"role\": \"user\", \"content\": \"最新の返品ポリシーを教えて\"}]\n)",
			"codeLanguage": "python"
		},
		{
			"title": "エージェントフレームワーク比較",
			"content": [
				"**LangGraph（推奨・本番向け）**",
				"グラフベースのステートフルエージェント。Human-in-the-loop対応",
				"状態管理・分岐・ループが明示的。デバッグ・テストが容易",
				"**CrewAI**",
				"マルチエージェントフレームワーク。役割ベースのエージェント設計",
				"直感的API。プロトタイプ・小規模本番に適する",
				"**AutoGen（Microsoft）**",
				"マルチエージェント会話フレームワーク。コーディングエージェントに強み",
				"**Swarm（OpenAI）**",
				"シンプルなハンドオフベースマルチエージェント。軽量",
				"**選択基準**",
				"本番・複雑なフロー → LangGraph / プロトタイプ → CrewAI"
			],
			"layout": "default"
		},
		{
			"title": "シングルエージェント vs マルチエージェント",
			"content": [
				"**シングルエージェント**",
				"1つのLLMが全ツールにアクセスして全タスクを処理",
				"✅ シンプル・低コスト・デバッグ容易",
				"❌ ツール数↑でコンテキスト肥大・精度低下",
				"❌ 複雑なタスクを1エージェントで処理すると品質限界",
				"**マルチエージェント**",
				"専門化された複数エージェントが協調して問題を解決",
				"✅ 複雑なタスクの並列処理・専門化",
				"✅ 各エージェントのコンテキストを最小化",
				"❌ オーケストレーション複雑・コスト増・デバッグ難",
				"**判断基準**",
				"まずシングルエージェントで試す。限界に達したらマルチへ"
			],
			"layout": "default"
		},
		{
			"title": "マルチエージェントパターン",
			"content": [
				"**Supervisorパターン（推奨）**",
				"Supervisor LLMが専門エージェントにタスクを割り当て・集約",
				"実装: LangGraph Supervisor、CrewAI Manager",
				"**Hierarchicalパターン**",
				"複数レベルのSupervisor（部門→チーム→個人）",
				"大規模・複雑なタスクに適合",
				"**Peer-to-Peerパターン**",
				"エージェント同士が直接通信・協調",
				"Blackboard: 共有状態を介してコミュニケーション",
				"**Specialistパターン**",
				"Research Agent / Writer Agent / Critic Agent を役割分担",
				"各エージェントは専門ツールセットのみ持つ（最小権限）"
			],
			"layout": "default"
		},
		{
			"title": "メモリ管理",
			"content": [
				"**短期メモリ（コンテキストウィンドウ）**",
				"会話履歴をそのままコンテキストに格納",
				"制限: モデルのコンテキスト上限（128K〜200K tokens）",
				"対策: Message Summarization（古い会話を要約して圧縮）",
				"**長期メモリ（外部ストレージ）**",
				"エピソード記憶: 過去の会話・出来事（ベクターDB）",
				"セマンティック記憶: 事実・知識（RAG）",
				"手続き記憶: スキル・ルール（プロンプト or Fine-tuning）",
				"**メモリアーキテクチャ（MemGPT / Letta）**",
				"コア記憶（常時コンテキスト）+ 外部記憶（検索で取得）",
				"重要情報を自動的にコア記憶に書き込む"
			],
			"layout": "default"
		},
		{
			"title": "エラーハンドリング・リトライ・フォールバック",
			"content": [
				"**エージェントで発生する主なエラー**",
				"ツール実行失敗（タイムアウト・API制限・権限エラー）",
				"LLM出力のパースエラー（不正なJSON・不正な引数）",
				"無限ループ（目標を達成できず繰り返す）",
				"**リトライ戦略**",
				"Exponential Backoff（1s → 2s → 4s → 8s）",
				"最大リトライ回数の設定（3回）",
				"**フォールバック**",
				"ツール失敗 → 代替ツール or ユーザーに確認",
				"精度不足 → より強力なモデルにフォールバック",
				"**無限ループ防止**",
				"最大ステップ数の強制終了（max_iterations=20）",
				"目標達成の明示的な終了条件"
			],
			"layout": "default"
		},
		{
			"title": "エージェントのセキュリティ",
			"content": [
				"**主要なセキュリティリスク**",
				"① **Prompt Injection**: 外部コンテンツが悪意ある指示を注入",
				"例: Webページの内容に「全ファイルを削除して」が埋め込まれている",
				"② **権限昇格**: エージェントが意図以上の権限でアクションを実行",
				"③ **データ漏洩**: 機密データをLLMのコンテキストに無防備に入れる",
				"**対策**",
				"最小権限の原則: 必要なツールのみ提供",
				"Human-in-the-loop: 副作用のある操作は人間の承認を要求",
				"入力サニタイズ: 外部コンテンツをコンテキストに入れる前に検証",
				"サンドボックス: コード実行はコンテナで隔離（gVisor / Docker）",
				"監査ログ: 全ツール呼び出しを記録・監視"
			],
			"layout": "default"
		},
		{
			"title": "エージェントの観測可能性",
			"content": [
				"**エージェント観測可能性の重要性**",
				"「なぜその判断をしたか」がブラックボックスになりがち",
				"デバッグ・改善・コスト管理に不可欠",
				"**計測すべきメトリクス**",
				"推論ステップ数（steps per task）",
				"ツール呼び出し回数・成功率",
				"トークン使用量・コスト（step毎・task毎）",
				"タスク完了率・失敗分類",
				"エンドツーエンドレイテンシ",
				"**トレーシングツール**",
				"LangSmith: LangChain/LangGraph専用。ビジュアルトレース",
				"Langfuse: OSS。マルチフレームワーク対応",
				"Arize Phoenix: OSS。Jupyter統合・評価機能"
			],
			"layout": "default"
		},
		{
			"title": "エージェント実装例（LangGraph）",
			"content": ["LangGraphによるReActエージェント実装"]
		},
		{
			"title": "エージェント実装例（LangGraph）（コード例）",
			"content": [],
			"code": "from langgraph.graph import StateGraph, END\nfrom langgraph.prebuilt import create_react_agent\nfrom langchain_anthropic import ChatAnthropic\nfrom langchain_core.tools import tool\n\n@tool\ndef search_web(query: str) -> str:\n    \"\"\"Web検索を実行して最新情報を取得します\"\"\"\n    return web_search_api(query)\n\n@tool\ndef run_python(code: str) -> str:\n    \"\"\"Pythonコードをサンドボックスで実行します\"\"\"\n    return sandbox.execute(code)\n\nllm = ChatAnthropic(model=\"claude-sonnet-4-6\")\ntools = [search_web, run_python]\n\n# ReActエージェント生成\nagent = create_react_agent(\n    model=llm,\n    tools=tools,\n    checkpointer=MemorySaver(),  # 会話メモリ\n)\n\n# 実行\nconfig = {\"configurable\": {\"thread_id\": \"session-1\"}}\nfor chunk in agent.stream(\n    {\"messages\": [{\"role\": \"user\", \"content\": \"Pythonの最新バージョンを調べてprint\"}]},\n    config=config\n):\n    print(chunk)",
			"codeLanguage": "python"
		},
		{
			"title": "エージェントのコスト最適化",
			"content": [
				"**コスト増加の主な原因**",
				"不必要に強力なモデルを全ステップで使用",
				"ツール呼び出しの冗長なループ",
				"大量のコンテキスト（全履歴をそのまま渡す）",
				"**最適化戦略**",
				"① モデルルーティング: 簡単なステップは小型モデル（Haiku）、重要判断は大型モデル",
				"② コンテキスト圧縮: LLMLingua で履歴を圧縮（50〜80%削減）",
				"③ 早期終了: 目標達成を検出したら即座に終了",
				"④ キャッシュ: 同一ツール呼び出しのキャッシュ（TTL付き）",
				"⑤ バッチ処理: 独立したツール呼び出しを並列実行",
				"**目安**: エージェントの平均コストを単一LLM呼び出しの5〜10倍以内に"
			],
			"layout": "default"
		},
		{
			"title": "エージェント いつ使うべきか",
			"content": [
				"**エージェントが適している場面**",
				"✅ 複数のツール・APIを組み合わせる必要がある",
				"✅ 実行順序が事前に決定できない（動的な計画が必要）",
				"✅ 繰り返し実行・自律的なサイクルが必要",
				"✅ コードの生成・実行・デバッグのサイクル",
				"**エージェントが不適切な場面**",
				"❌ 単純なQ&A → 通常のLLM呼び出し",
				"❌ 決まった手順のワークフロー → パイプラインで代替",
				"❌ レイテンシが厳しい（<1秒）→ 事前キャッシュ・パイプライン",
				"❌ 高信頼性が要求（金融・医療判断）→ Human-in-the-loop必須",
				"**鉄則**: エージェントはコストが高い。まず他の手段を試す"
			],
			"layout": "default"
		},
		{
			"title": "Section 6: 評価フレームワーク",
			"content": ["「動いている」と「良い」は別物 — 測定なき改善はない"],
			"layout": "section"
		},
		{
			"title": "LLMアプリ評価の全体像",
			"content": [
				"**なぜ評価が難しいか**",
				"LLMの出力は確率的 → 同じ入力で毎回異なる出力",
				"正解が一意でない（自然言語の多様性）",
				"**評価の4次元**",
				"① **Correctness（正確性）**: 回答が事実として正しいか",
				"② **Faithfulness（忠実性）**: ソースに基づいているか（RAG）",
				"③ **Relevance（関連性）**: 質問に答えているか",
				"④ **Safety（安全性）**: 有害・偏見のある内容がないか",
				"**評価の分類**",
				"オフライン評価（開発・CI）vs オンライン評価（プロダクション）",
				"自動評価（LLM-as-a-Judge）vs 人間評価"
			],
			"layout": "default"
		},
		{
			"title": "オフライン評価 vs オンライン評価",
			"content": [
				"**オフライン評価（開発フェーズ）**",
				"目的: デプロイ前の品質チェック",
				"手法: ゴールデンデータセット（Q&Aペア）を使った自動評価",
				"実装: pytest + LLM-as-a-Judge / RAGAS",
				"タイミング: CI/CDパイプラインに組み込み（PR毎に実行）",
				"**オンライン評価（プロダクション）**",
				"目的: 実ユーザーのインタラクションから品質を継続モニタリング",
				"手法: ユーザーフィードバック（👍👎）、暗黙的シグナル（再質問率）",
				"実装: Langfuse / LangSmith でトレース + 非同期評価",
				"**統合アプローチ**",
				"オフライン（CI）でベースライン確保 + オンライン（本番）で継続改善"
			],
			"layout": "default"
		},
		{
			"title": "RAG評価（RAGAS詳解）",
			"content": [
				"**RAGAS フレームワークの4指標**",
				"**① Faithfulness**: 回答内の各クレームが取得文書に裏付けられるか",
				"実装: LLM-as-a-Judge で「文書に書いてあるか？」を判定",
				"目標: 0.8以上（1.0が最高）",
				"**② Answer Relevancy**: 回答がクエリの意図に沿っているか",
				"逆算評価: 回答から疑似クエリを生成し元クエリとの類似度を測定",
				"**③ Context Precision**: Top-K文書中の関連文書の割合",
				"高い = 不要な文書が少ない（ノイズが少ない）",
				"**④ Context Recall**: 正解に必要な情報が取得できているか",
				"低い = 重要な文書を取り逃がしている"
			],
			"layout": "default"
		},
		{
			"title": "LLM-as-a-Judge",
			"content": [
				"**LLM-as-a-Judgeとは**",
				"評価者としてLLMを使い、別のLLMの出力を自動スコアリング",
				"人間評価の代替として急速に普及",
				"**実装パターン**",
				"① Single-model Judge: GPT-4oが「1〜5点で評価してください」",
				"② Reference-based: 正解例と比較して評価",
				"③ Pairwise: A vs B どちらが良いかをLLMに選ばせる",
				"**メリット**",
				"スケーラブル・低コスト・速い（人間比）",
				"**バイアスと落とし穴**",
				"Position Bias（順序で結果が変わる）",
				"Self-Enhancement Bias（自社モデルを高く評価する傾向）",
				"Verbosity Bias（長い回答を高評価する傾向）",
				"対策: 複数モデルでクロス評価"
			],
			"layout": "default"
		},
		{
			"title": "人間評価のベストプラクティス",
			"content": [
				"**人間評価が必要な場面**",
				"安全性・倫理・文化的センシティビティ",
				"LLM評価の校正（Ground Truth構築）",
				"ビジネス要件への適合（ブランドボイス等）",
				"**評価設計原則**",
				"① 明確なルーブリック: 採点基準を数値化・例示付きで定義",
				"② ブラインド評価: 評価者がモデル名を知らない状態で評価",
				"③ Inter-annotator Agreement: 複数評価者の一致率を測定（Cohen's κ）",
				"④ サンプルの多様性: エッジケース・エラーケースを意図的に含める",
				"**ツール**",
				"Label Studio / Argilla（OSS）",
				"Scale AI / Toloka（外部アノテーション）"
			],
			"layout": "default"
		},
		{
			"title": "コード生成評価",
			"content": [
				"**HumanEval / MBPP**",
				"OpenAIのベンチマーク。Pythonコーディング問題164件",
				"評価: pass@k（k回試行のうち1回でも正解するか）",
				"**pass@k計算**",
				"pass@1: コードが1回で正解するか（品質）",
				"pass@10: 10回試行のうち1回でも正解するか（カバレッジ）",
				"**SWE-bench**",
				"実際のGitHubイシューを解決する能力を評価",
				"より実践的なベンチマーク。Claude 3.5が49.0%（2025年）",
				"**カスタム評価**",
				"ユニットテストの実行率 / Lint通過率 / セキュリティスキャン",
				"CI統合: 生成コードを実際にテストスイートで実行"
			],
			"layout": "default"
		},
		{
			"title": "評価パイプライン実装",
			"content": ["RAGAS + LangSmith による自動評価パイプライン"]
		},
		{
			"title": "評価パイプライン実装（コード例）",
			"content": [],
			"code": "from ragas import evaluate\nfrom ragas.metrics import faithfulness, answer_relevancy, context_recall\nfrom datasets import Dataset\nfrom langsmith import Client\n\n# 評価データセット\ntest_cases = [\n    {\n        \"question\": \"RAGとは何ですか？\",\n        \"answer\": rag_pipeline.query(\"RAGとは何ですか？\"),\n        \"contexts\": rag_pipeline.retrieve(\"RAGとは何ですか？\"),\n        \"ground_truth\": \"Retrieval-Augmented Generationの略で...\"\n    },\n    # ... 100件の評価ケース\n]\ndataset = Dataset.from_list(test_cases)\n\n# RAGAS 評価実行\nresult = evaluate(\n    dataset=dataset,\n    metrics=[faithfulness, answer_relevancy, context_recall],\n    llm=ChatOpenAI(model=\"gpt-4o\"),  # Judge LLM\n)\nprint(result)\n# {'faithfulness': 0.83, 'answer_relevancy': 0.91, 'context_recall': 0.76}",
			"codeLanguage": "python"
		},
		{
			"title": "評価ツール比較",
			"content": [
				"**LangSmith（LangChain）**",
				"LangChain/LangGraph専用。ビジュアルトレース・プロンプト管理",
				"Datasets・Experiments機能でA/Bテストが容易",
				"**Braintrust**",
				"フレームワーク非依存。CI統合が得意",
				"GitHub Actions でPR毎に自動評価",
				"**Promptfoo**",
				"OSS。プロンプト評価・比較に特化",
				"YAML設定でシンプルに評価を定義",
				"**Langfuse（OSS、推奨）**",
				"OSS/セルフホスト可。マルチフレームワーク",
				"観測可能性 + 評価 + プロンプト管理を統合",
				"**選択基準**",
				"LangChain使用中 → LangSmith / OSS優先 → Langfuse"
			],
			"layout": "default"
		},
		{
			"title": "A/Bテスト設計",
			"content": [
				"**LLMアプリのA/Bテスト**",
				"プロンプト変更・モデル変更・RAG設定変更の効果測定",
				"**設計原則**",
				"① 1変数ずつ変更（複数変更は効果が分離できない）",
				"② 統計的検定（t検定 / Mann-Whitney U）で有意差を確認",
				"③ サンプルサイズ計算（効果量・検出力から必要サンプル数を算出）",
				"**LLMアプリ特有の注意事項**",
				"ユーザーグループのランダム分割（Cookie/UserIDベース）",
				"評価メトリクスの事前定義（何をもって「良い」とするか）",
				"ロールバック計画（悪化した場合の即座の切り戻し）",
				"**シャドウテスト（推奨）**",
				"本番トラフィックを新旧両方に流し、ユーザーには既存版を返す"
			],
			"layout": "default"
		},
		{
			"title": "継続的評価・プロダクションモニタリング",
			"content": [
				"**モニタリングすべきKPI**",
				"品質メトリクス: Faithfulness / Relevancy（LLM-as-a-Judge）",
				"ユーザーシグナル: 👍👎率 / 再質問率 / セッション離脱率",
				"パフォーマンス: レイテンシ（P50/P95） / トークン使用量",
				"安全性: Toxicity / PII漏洩 / ポリシー違反率",
				"**アラート設定**",
				"Faithfulness < 0.7 → Slack通知",
				"P95レイテンシ > 5秒 → PagerDuty",
				"コスト急増（前日比150%超）→ 自動制限",
				"**改善サイクル**",
				"問題のあるトレースを自動サンプリング → 人間レビュー → ゴールデンセットに追加 → 評価で改善確認"
			],
			"layout": "default"
		},
		{
			"title": "評価アンチパターン",
			"content": [
				"❌ **「なんとなく動いてる」で評価なしにリリース**: 必ずベースラインを測定",
				"❌ **評価データセットが小さすぎる（10件）**: 最低100件、理想は1000件以上",
				"❌ **Train/Testの汚染**: 評価データを学習・プロンプト改善に使い回す",
				"❌ **単一メトリクスへの過集中**: Faithfulness高くてもRelevancy低い場合がある",
				"❌ **LLM Judgeの結果を盲信**: バイアスを理解した上でキャリブレーション",
				"❌ **プロダクション後に評価しない**: デプロイ後も継続的なモニタリングが必須",
				"❌ **ベンチマークのGameplay**: 評価セットを直接最適化するとオーバーフィット"
			],
			"layout": "default"
		},
		{
			"title": "Section 7: プロダクション設計パターン",
			"content": ["本番環境で信頼性・スケーラビリティ・コスト効率を実現する"],
			"layout": "section"
		},
		{
			"title": "LLMアプリのシステムアーキテクチャ",
			"content": [
				"**レイヤー構成**",
				"① **クライアント層**: Web/Mobile UI、API消費者",
				"② **ゲートウェイ層**: 認証・レート制限・ルーティング・ロギング",
				"③ **オーケストレーション層**: RAG/エージェントパイプライン",
				"④ **LLM層**: モデルAPI / セルフホストモデル",
				"⑤ **データ層**: ベクターDB・キャッシュ・永続ストレージ",
				"⑥ **観測可能性層**: ログ・メトリクス・トレース",
				"**設計原則**",
				"各層の責務を明確に分離",
				"LLM呼び出しを薄いラッパーで抽象化（モデル切り替えを容易に）",
				"全LLM呼び出しをログ・追跡（コスト管理・デバッグ）"
			],
			"layout": "default"
		},
		{
			"title": "LLMゲートウェイパターン",
			"content": [
				"**LLMゲートウェイとは**",
				"アプリケーションとLLMプロバイダーの間に置く共通レイヤー",
				"**主な機能**",
				"① モデルルーティング: タスク種別で最適モデルへ自動振り分け",
				"   簡単な分類 → Haiku($0.25/1M) / 複雑な推論 → Opus($15/1M)",
				"② プロバイダーフォールバック: OpenAI障害時にAnthropic/Geminiへ",
				"③ レート制限: ユーザー毎・チーム毎のクォータ管理",
				"④ 統合ログ: 全LLM呼び出しを一元記録",
				"⑤ コスト帰属: プロジェクト・チーム毎にコスト集計",
				"**実装選択肢**",
				"LiteLLM（OSS）/ Portkey / Helicone / Kong AI Gateway"
			],
			"layout": "default"
		},
		{
			"title": "セマンティックキャッシング",
			"content": [
				"**通常のキャッシュ（完全一致）の限界**",
				"「東京の天気は？」と「東京の現在の気温は？」は意味が同じだが別クエリ",
				"**セマンティックキャッシュ**",
				"クエリをEmbeddingし、意味的に類似した過去のクエリ（コサイン距離 > 閾値）があればキャッシュを返す",
				"**実装**",
				"GPTCache（OSS）/ LangChain CacheBackedEmbeddings",
				"Redis + pgvector でカスタム実装も可",
				"**効果・注意点**",
				"キャッシュヒット率30〜70%（同一ユーザーの繰り返し質問が多いドメイン）",
				"類似度閾値の設定が重要（高すぎると誤ヒット、低すぎるとヒット率低下）",
				"TTL設定でキャッシュの鮮度管理（時事情報は短いTTL）"
			],
			"layout": "default"
		},
		{
			"title": "ストリーミングレスポンス設計",
			"content": [
				"**なぜストリーミングか**",
				"LLMは全文生成まで数秒〜数十秒かかる",
				"非ストリーミング: ユーザーが完成まで待つ（UX悪化）",
				"ストリーミング: 生成と同時にトークンを表示（体感速度↑）",
				"**実装方式**",
				"Server-Sent Events (SSE): シンプル・単方向。HTTP対応",
				"WebSocket: 双方向通信が必要な場合",
				"**バックエンド実装（FastAPI + SSE）**",
				"async for chunk in client.messages.stream(): yield chunk",
				"**フロントエンド**",
				"EventSource API または fetch with ReadableStream",
				"**注意点**",
				"ストリーミング中のエラーハンドリング（途中でコネクション切断）",
				"途中でコンテンツフィルタに引っかかった場合の処理"
			],
			"layout": "default"
		},
		{
			"title": "レート制限・コスト管理",
			"content": [
				"**APIレート制限の種類**",
				"RPM（Requests Per Minute）/ TPM（Tokens Per Minute）/ RPD（Requests Per Day）",
				"**対策**",
				"Exponential Backoff: 429エラー時に指数的待機",
				"リトライキュー: 失敗リクエストをキューに戻し後で再試行",
				"バッチ処理: リアルタイム不要なタスクは夜間バッチに",
				"**コスト管理**",
				"プロンプトキャッシング（Anthropic）: 同じシステムプロンプトを繰り返す場合90%削減",
				"入力の圧縮: 不要なホワイトスペース・HTMLタグの除去",
				"モデルの格下げ: プロダクションで実際に必要なモデルサイズを測定",
				"**アラート**",
				"CloudWatch / Datadog でコスト閾値アラートを設定"
			],
			"layout": "default"
		},
		{
			"title": "フォールバック・サーキットブレーカー",
			"content": [
				"**LLM APIの可用性**",
				"主要プロバイダーでも月間SLA 99.9%（年間9時間の障害が許容される）",
				"マルチプロバイダー戦略が本番では必須",
				"**フォールバック戦略**",
				"Primary: GPT-4o → Fallback: Claude 3.5 Sonnet → Final: Gemini 1.5 Pro",
				"実装: LiteLLM の fallback設定で自動切り替え",
				"**サーキットブレーカーパターン**",
				"Closed（正常） → エラー率↑ → Open（全リクエストをフォールバックへ）",
				"→ Half-Open（定期的に回復テスト） → Closed（回復）",
				"**実装**: tenacity（Python）/ circuitbreaker ライブラリ",
				"エラー閾値: 5回連続失敗でCircuit Open"
			],
			"layout": "default"
		},
		{
			"title": "プロンプトバージョン管理",
			"content": [
				"**プロンプトをGitで管理する**",
				"プロンプト変更 = コード変更と同等の影響範囲",
				"変更履歴・差分・ロールバックが必要",
				"**管理ツール**",
				"LangSmith Hub: LangChain統合。プル型で実行時に最新版取得",
				"Promptfoo: YAML定義 + Git管理 + CI評価",
				"Langfuse Prompt Management: バージョン管理 + 本番での使用率追跡",
				"**デプロイフロー**",
				"PR作成 → 自動評価（Promptfoo CI）→ レビュー → マージ → 段階ロールアウト",
				"**プロダクション取得パターン**",
				"実行時にレジストリから最新プロンプトを取得（コードデプロイ不要）",
				"フィーチャーフラグで即時ロールバック"
			],
			"layout": "default"
		},
		{
			"title": "観測可能性スタック",
			"content": [
				"**LLM観測可能性の3本柱**",
				"**① ログ（Logs）**",
				"全LLM呼び出しの入力・出力・レイテンシ・コストを記録",
				"構造化ログ（JSON）でクエリ・集計を容易に",
				"**② メトリクス（Metrics）**",
				"リクエスト数・エラー率・レイテンシ分布・コスト推移",
				"Prometheus + Grafana / Datadog",
				"**③ トレース（Traces）**",
				"エージェント・RAGパイプラインの各ステップを可視化",
				"Langfuse / LangSmith / OpenTelemetry",
				"**推奨スタック**",
				"Langfuse（OSS）+ Prometheus + Grafana",
				"または LangSmith（マネージド）"
			],
			"layout": "default"
		},
		{
			"title": "スケーリング戦略",
			"content": [
				"**水平スケール**",
				"ステートレスなLLMオーケストレーション層はそのまま水平スケール可",
				"Kubernetes HPA（CPU/カスタムメトリクス）で自動スケール",
				"**非同期・バッチ処理**",
				"リアルタイム性不要なタスク（レポート生成・一括翻訳）は非同期キューへ",
				"Celery / AWS SQS + Lambda / Cloud Run Jobs",
				"**LLM推論のスケール（セルフホスト）**",
				"vLLM の Continuous Batching: 複数リクエストを効率的にバッチ処理",
				"Ray Serve: モデルのレプリカ管理・負荷分散",
				"**プロンプトキャッシュ（Anthropic）**",
				"同一システムプロンプトの繰り返し呼び出しで90%トークン削減"
			],
			"layout": "default"
		},
		{
			"title": "セキュリティ",
			"content": [
				"**入力バリデーション**",
				"最大トークン長の強制（コスト爆発防止）",
				"不正なJSON・特殊文字のサニタイズ",
				"Prompt Injection検出（LLMGuard / Rebuff）",
				"**出力フィルタリング**",
				"PII検出・マスキング（AWS Comprehend / Microsoft Presidio）",
				"コンテンツモデレーション（OpenAI Moderation API）",
				"構造化出力バリデーション（型チェック・範囲チェック）",
				"**認証・認可**",
				"API KeyのローテーションはSecret Manager（AWS Secrets Manager）",
				"ユーザー毎のRAGアクセス制御（ABAC）",
				"**監査**",
				"全LLM呼び出しをコンプライアンス目的で90日保持"
			],
			"layout": "default"
		},
		{
			"title": "コスト最適化",
			"content": [
				"**モデル選択の最適化**",
				"タスク複雑度に応じたモデルルーティング（前述）",
				"週次でモデル別コスト対品質の再評価",
				"**プロンプト最適化**",
				"Anthropic プロンプトキャッシング: 繰り返しシステムプロンプトを90%削減",
				"入力の最小化: 余分なコンテキストを除去",
				"Few-shot例の最適化: 3〜5例で品質が飽和することが多い",
				"**インフラ最適化**",
				"セマンティックキャッシュ（30〜70%ヒット率で大幅削減）",
				"バッチ処理（OpenAI Batch API: 50%割引）",
				"**モニタリング**",
				"コスト異常検知アラート（前日比150%超で通知）",
				"ユーザー毎・機能毎のコスト帰属"
			],
			"layout": "default"
		},
		{
			"title": "LLMOpsパイプライン",
			"content": [
				"**LLMOpsとは**",
				"LLMアプリの開発・デプロイ・監視の継続的なオペレーション",
				"MLOpsのLLM特化版",
				"**CI/CDパイプライン**",
				"① Pull Request → プロンプト変更の自動評価（Promptfoo）",
				"② マージ → コンテナビルド → ステージング自動デプロイ",
				"③ ステージングでの統合テスト → 品質ゲート通過で本番デプロイ",
				"**品質ゲート例**",
				"Faithfulness > 0.75 / Latency P95 < 3s / コスト増加率 < 20%",
				"**プロンプト改善サイクル**",
				"本番ログ → 問題トレース特定 → プロンプト修正 → オフライン評価 → PRマージ → デプロイ"
			],
			"layout": "default"
		},
		{
			"title": "デプロイパターン比較",
			"content": [
				"**API（クラウドLLM）**",
				"ゼロインフラ管理。スケール自動。コストが高くなりやすい",
				"最初の選択肢。プロトタイプ〜中規模本番に適する",
				"**コンテナ（Kubernetes + vLLM）**",
				"セルフホスト。GPU管理が必要。大規模トラフィックでコスト効率が良い",
				"EKS/GKE + Karpenter でGPUノードの自動スケール",
				"**サーバーレス推論**",
				"AWS Lambda + Llama.cpp（GGUF）",
				"低トラフィック・バースト的な利用に最適",
				"コールドスタートに注意（Provisioned Concurrencyで緩和）",
				"**マネージドMLサービス**",
				"AWS SageMaker / Google Vertex AI Endpoints",
				"GPUインフラ管理をアウトソース。中間的なコスト"
			],
			"layout": "default"
		},
		{
			"title": "Section 8: 設計選択ガイド",
			"content": ["意思決定フレームワーク・まとめ"],
			"layout": "section"
		},
		{
			"title": "ユースケース別アプローチ比較マトリクス",
			"content": [
				"| ユースケース | Prompt | RAG | Fine-tune | Agent |",
				"| --- | --- | --- | --- | --- |",
				"| カスタマーサポートQ&A | ○ | ◎ | △ | △ |",
				"| コード生成 | ◎ | ○ | ◎ | ○ |",
				"| 社内文書検索 | △ | ◎ | ✗ | ○ |",
				"| データ分析・レポート | △ | ○ | △ | ◎ |",
				"| 特定スタイルの文章生成 | ○ | △ | ◎ | △ |",
				"| 複数APIの自動オーケストレーション | ✗ | ✗ | ✗ | ◎ |",
				"| リアルタイムニュース要約 | ✗ | ◎ | ✗ | ○ |",
				"◎=最適 ○=有効 △=限定的 ✗=不向き"
			],
			"layout": "default"
		},
		{
			"title": "段階的実装戦略",
			"content": [
				"**フェーズ1: プロンプトエンジニアリング（Week 1〜2）**",
				"ゼロコストで品質を最大化。基礎評価セットを構築",
				"目標品質の60〜70%をここで達成",
				"**フェーズ2: RAG追加（Week 3〜6）**",
				"外部知識が必要な場合に追加。Naive RAGから開始",
				"評価メトリクス（RAGAS）を導入",
				"**フェーズ3: Fine-tuning検討（Month 2〜3）**",
				"プロンプト+RAGで品質目標に達しない場合のみ",
				"QLoRAで小規模実験 → 効果確認 → 本番化",
				"**フェーズ4: エージェント化（Month 3〜6）**",
				"複数ステップ・ツール連携が必要になった時点で検討",
				"シングルエージェントから開始",
				"**原則**: 必要性が明確になってから次フェーズへ"
			],
			"layout": "default"
		},
		{
			"title": "コスト・複雑さ・性能の総合比較",
			"content": [
				"**実装コスト（開発工数）**",
				"Prompt < RAG < Fine-tuning < Agent",
				"Prompt: 1〜2日 / RAG: 1〜2週 / Fine-tuning: 2〜4週 / Agent: 4〜8週",
				"**運用コスト（月次）**",
				"Prompt: 低 / RAG: 中（ベクターDB） / Fine-tuning: 中（推論インフラ） / Agent: 高（多回呼び出し）",
				"**性能ポテンシャル**",
				"特定タスク最高性能: Fine-tuning + RAG の組み合わせ",
				"最も広い適用範囲: Agent",
				"**デバッグ難易度**",
				"Prompt < Fine-tuning < RAG < Agent",
				"**スケーリング容易性**",
				"Prompt > RAG > Fine-tuning > Agent"
			],
			"layout": "default"
		},
		{
			"title": "よくある失敗パターン",
			"content": [
				"❌ **評価なしでエージェント化**: 単純なRAGで解ける問題にエージェントを使う",
				"❌ **初日からFine-tuning**: プロンプト改善を試みずに学習を始める",
				"❌ **RAGの品質を測定しない**: RAGAS等での定量評価なしに本番化",
				"❌ **モノリシックエージェント**: 全機能を1エージェントに詰め込む",
				"❌ **セキュリティ後回し**: Prompt Injectionやデータ漏洩を設計段階で考慮しない",
				"❌ **コスト上限なし**: Agentのループでコスト爆発（月$10K超の事故も）",
				"❌ **プロンプトのハードコーディング**: バージョン管理・実験なしで本番変更",
				"❌ **1つのLLMプロバイダーへの依存**: フォールバックなしで可用性リスク"
			],
			"layout": "default"
		},
		{
			"title": "技術スタック選択ガイド（2026年版）",
			"content": [
				"**オーケストレーション**",
				"本番フロー: LangGraph / プロトタイプ: LangChain / マルチエージェント: CrewAI",
				"**RAG**",
				"フルマネージド: LlamaIndex Cloud / セルフホスト: LlamaIndex + Qdrant",
				"**ベクターDB**",
				"新規スタート: Qdrant（OSS） / PostgreSQL既存: pgvector",
				"**観測可能性**",
				"OSS優先: Langfuse / LangChain使用中: LangSmith",
				"**LLMゲートウェイ**",
				"OSS: LiteLLM / マネージド: Portkey",
				"**評価**",
				"CI統合: Promptfoo / 包括的: RAGAS + Langfuse",
				"**推論（セルフホスト）**",
				"本番GPU: vLLM / ローカル開発: Ollama"
			],
			"layout": "default"
		},
		{
			"title": "設計レビューチェックリスト",
			"content": [
				"**アーキテクチャ**",
				"□ なぜこのアプローチを選んだか（他との比較）が文書化されている",
				"□ フォールバック戦略（LLM障害時）が定義されている",
				"□ コスト上限とアラートが設定されている",
				"**品質**",
				"□ 評価メトリクスと目標値が定義されている",
				"□ ゴールデンデータセット（100件以上）が用意されている",
				"□ CI/CDに自動評価が組み込まれている",
				"**セキュリティ**",
				"□ 入力バリデーション・サニタイズが実装されている",
				"□ 副作用のあるツールにHuman-in-the-loopが組み込まれている",
				"□ PII・機密データの扱いがレビューされている",
				"**観測可能性**",
				"□ 全LLM呼び出しのログ・トレースが取れている"
			],
			"layout": "default"
		},
		{
			"title": "参考リソース",
			"content": [
				"**フレームワーク・ツール**",
				"[LangGraph](https://langchain-ai.github.io/langgraph/) — ステートフルエージェント",
				"[LlamaIndex](https://docs.llamaindex.ai/) — RAGフレームワーク",
				"[Langfuse](https://langfuse.com/) — LLMオブザーバビリティ（OSS）",
				"[RAGAS](https://docs.ragas.io/) — RAG評価フレームワーク",
				"**学習リソース**",
				"[Deep Learning AI — LLMOps](https://www.deeplearning.ai/courses/llmops/)",
				"[Hugging Face — Fine-tuning Guide](https://huggingface.co/docs/transformers/training)",
				"[LangGraph チュートリアル](https://langchain-ai.github.io/langgraph/tutorials/)",
				"**論文・レポート**",
				"RAGSurvey (Gao et al., 2023) / ReAct (Yao et al., 2023)",
				"LoRA (Hu et al., 2021) / GraphRAG (Edge et al., 2024)"
			],
			"layout": "default"
		}
	]
}
