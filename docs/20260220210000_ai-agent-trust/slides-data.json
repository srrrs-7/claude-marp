{
	"slides": [
		{
			"title": "AIエージェントの信頼問題：自律型AIをどう信頼するか",
			"layout": "center",
			"content": [
				"AI Agent Trust Problem",
				"",
				"自律的に行動するAIに、どこまで権限を委譲すべきか"
			]
		},
		{
			"title": "Agenda",
			"layout": "default",
			"content": [
				"- 1. AIエージェントの台頭",
				"- 2. 信頼の哲学：人間は何を信頼しているのか",
				"- 3. AIエージェントの権限設計",
				"- 4. 「信頼するが検証する」パターン",
				"- 5. 事故事例と教訓",
				"- 6. 信頼のエンジニアリング"
			]
		},
		{
			"title": "AIエージェントの台頭",
			"layout": "section",
			"content": ["Chapter 1: Rise of AI Agents"]
		},
		{
			"title": "2026年: AIエージェントの時代",
			"layout": "default",
			"content": [
				"- **Claude Code**: 自律的にコードを読み書き、テストを実行",
				"- **Devin**: AIソフトウェアエンジニア（タスクを自律的に完了）",
				"- **AutoGPT / CrewAI**: 複数エージェントの協調動作",
				"- **MCP (Model Context Protocol)**: エージェントのツール統合標準",
				"- 共通点: AIが **自律的に判断し行動** する",
				"- 問題: 自律的な行動を **どこまで信頼** できるのか"
			]
		},
		{
			"title": "信頼の哲学",
			"layout": "section",
			"content": ["Chapter 2: Philosophy of Trust"]
		},
		{
			"title": "信頼とは何か",
			"layout": "default",
			"content": [
				"- **信頼 = 脆弱性の受容**: 相手が裏切る可能性を受け入れること",
				"- 人間の信頼は **能力 × 誠実さ × 予測可能性** で構成",
				"- AI に「誠実さ」はあるか? → ない。しかし「予測可能性」はある",
				"- **適切な信頼** (Appropriate Trust): 過信でも不信でもない適度な信頼",
				"- 「AIを信頼する」= 「AIの能力範囲と限界を正確に理解する」",
				"- Over-trust (過信) と Under-trust (不信) の両方が危険"
			]
		},
		{
			"title": "人間がAIを過信するメカニズム",
			"layout": "default",
			"content": [
				"- **Automation Bias**: 自動化された判断を無批判に信頼する傾向",
				"- **流暢さバイアス**: 自然な文章 = 正しい内容と錯覚",
				"- **Anchoring**: AIの最初の提案に固執する",
				"- **Complacency**: AIが普段正しい → 異常時にも信頼してしまう",
				"- テスラ Autopilot事故: **Lv2自動運転なのにLv5として信頼**",
				"- 航空機の自動操縦: 信頼管理に **50年の知見** がある"
			]
		},
		{
			"title": "AIエージェントの権限設計",
			"layout": "section",
			"content": ["Chapter 3: Permission Design"]
		},
		{
			"title": "最小権限の原則（PoLP for AI）",
			"layout": "default",
			"content": [
				"- **最小権限 (Principle of Least Privilege)**: IAMの基本原則",
				"- AIエージェントにも同じ原則を適用すべき",
				"- **Read-Only Mode**: 情報取得のみ、変更不可（最低レベル）",
				"- **Sandboxed Execution**: 隔離環境で実行（テスト・開発）",
				"- **Human-in-the-Loop**: 重要操作には人間の承認が必要",
				"- **Full Autonomy**: 完全自律（高度に検証された限定タスクのみ）"
			]
		},
		{
			"title": "AIエージェント信頼レベル",
			"layout": "default",
			"content": ["![w:800 center](assets/diagram-01-trust-levels.svg)"]
		},
		{
			"title": "信頼レベルのエスカレーション",
			"layout": "default",
			"content": ["- AIエージェントへの信頼は段階的に構築すべき"],
			"code": "// Trust Escalation Pattern\nconst trustLevels = {\n  L0_observe: { read: true, write: false, execute: false },\n  L1_suggest: { read: true, write: false, suggest: true },\n  L2_sandbox: { read: true, write: 'sandbox', execute: 'sandbox' },\n  L3_guarded: { read: true, write: true, execute: 'with-approval' },\n  L4_autonomous: { read: true, write: true, execute: true },\n};\n// Start at L0, escalate only with evidence of reliability",
			"codeLanguage": "typescript"
		},
		{
			"title": "「信頼するが検証する」パターン",
			"layout": "section",
			"content": ["Chapter 4: Trust but Verify"]
		},
		{
			"title": "Trust but Verify（信頼するが検証する）",
			"layout": "default",
			"content": [
				"- ロナルド・レーガンの核軍縮交渉のフレーズ",
				"- AIエージェントに最も適した信頼モデル",
				"- **Pre-execution Review**: 実行前にAIの計画を人間がレビュー",
				"- **Post-execution Audit**: 実行後にAIの行動ログを監査",
				"- **Continuous Monitoring**: AIの振る舞いをリアルタイム監視",
				"- **Rollback Capability**: AIの行動を巻き戻せる設計"
			]
		},
		{
			"title": "Trust but Verify パターン図解",
			"layout": "default",
			"content": ["![w:800 center](assets/diagram-02-trust-verify.svg)"]
		},
		{
			"title": "事故事例と教訓",
			"layout": "section",
			"content": ["Chapter 5: Incidents and Lessons"]
		},
		{
			"title": "AIエージェント事故事例",
			"layout": "default",
			"content": [
				"- **ファイル削除事故**: AIがクリーンアップ中に重要ファイルを削除",
				"- **無限ループ課金**: AIエージェントがAPI呼び出しを無限ループ → $10K請求",
				"- **機密情報漏洩**: AIが内部コードをパブリックリポジトリにpush",
				"- **カスケード障害**: AIが「修正」のつもりで本番DBスキーマを変更",
				"- 共通原因: **過剰な権限** × **不十分な監視** × **ロールバック不能**",
				"- 対策: 権限制限、サンドボックス、承認フロー、監査ログ"
			]
		},
		{
			"title": "信頼のエンジニアリング",
			"layout": "section",
			"content": ["Chapter 6: Engineering Trust"]
		},
		{
			"title": "AIエージェントの信頼設計チェックリスト",
			"layout": "default",
			"content": [
				"- 1. **権限の最小化**: AIに必要最小限の権限のみ付与",
				"- 2. **段階的信頼**: 実績に基づいて権限を段階的にエスカレート",
				"- 3. **可観測性**: 全てのAI行動をログに記録、監査可能に",
				"- 4. **ロールバック**: AIの全操作を元に戻せる設計",
				"- 5. **Kill Switch**: 緊急時にAIを即座に停止できるメカニズム",
				"- 6. **定期レビュー**: AIの権限レベルを定期的に見直す"
			]
		},
		{
			"title": "AIエージェント信頼設計の6原則",
			"layout": "default",
			"content": ["![w:800 center](assets/diagram-03-checklist.svg)"]
		},
		{
			"title": "まとめ：信頼は設計するもの",
			"layout": "center",
			"content": [
				"AIエージェントへの信頼は「感情」ではなく「設計」の問題",
				"",
				"過信は事故を招き、不信は価値を失う",
				"",
				"最小権限 × 段階的信頼 × 検証可能性",
				"",
				"**Trust but Verify — 信頼するが、常に検証せよ**"
			]
		}
	]
}
