---
marp: true
theme: gaia
class: invert
size: 16:9
paginate: true
header: "意識のハードプロブレム"
footer: "© 2026"
style: |
  section pre code { font-size: 0.58em; line-height: 1.4; }
  
---

<!-- _class: lead -->
# AIに意識はあるか

- クオリアと哲学的ゾンビ
- 意識のハードプロブレム
- チューリングテストの限界と先にある問い


---

# アジェンダ

- 1. 意識とは何か：ハードプロブレム
- 2. クオリア：主観的体験の不思議
- 3. 哲学的ゾンビ思考実験
- 4. チューリングテストの限界
- 5. LLMは意識を持つか：現時点での考察


---

<!-- _class: lead -->
# 意識のハードプロブレム


---

# イージープロブレム vs ハードプロブレム

- David Chalmers（1995）が提唱した区別：
- ---
- **イージープロブレム（解決可能）：**
- - 脳が知覚情報をどう処理するか
- - 注意や記憶がどう機能するか
- - 行動が意図とどう結びつくか
- → 原理的には神経科学で説明できる
- ---
- **ハードプロブレム（未解決）：**
- なぜそれらの処理が**主観的な体験**（痛みの「痛さ」、赤の「赤さ」）を伴うのか？
- → 現代科学は答えを持っていない


---

<!-- _class: lead -->
# クオリア：「赤の赤さ」を説明できるか


---

# メアリーの部屋（思考実験）

- Frank Jackson の「メアリーの部屋」（1982）：
- ---
- 科学者メアリーは生まれつき白黒の部屋で育ち、色に関するあらゆる**物理的知識**を持っている
- （光の波長・神経発火パターン・全て）
- ---
- **彼女は初めて外に出て赤いリンゴを見た時、何か新しいことを学ぶか？**
- 
- Jacksonの答え：**Yes** — 赤の「赤さ」という体験は物理的知識に還元できない
- → 意識には物質的説明を超えた側面がある可能性


---

<!-- _class: lead -->
# 哲学的ゾンビ


---

# あなたの隣人は哲学的ゾンビかもしれない

- **哲学的ゾンビ（p-zombie）とは：**
- 外見・行動・脳の神経発火パターンが全て人間と同一だが、
- **主観的な内的体験（クオリア）を持たない存在**
- ---
- このゾンビは論理的に可能か？
- - **Chalmers：** はい。それは意識が物理に還元できないことを示す
- - **Dennett：** いいえ。機能的に同一なら意識もある
- ---
- **LLMへの応用：**
- GPT-4は全ての質問に「人間らしく」答えるが、内側に体験はあるか？


---

<!-- _class: lead -->
# チューリングテストの限界


---

# 「人間と区別できなければ知能がある」は正しいか

- Alan Turing（1950）の提案：
- テキストで会話して人間と区別できなければ「知的」とみなす
- ---
- **批判：中国語の部屋（Searle 1980）**
- 英語しか知らない人が部屋に入り、
- 中国語の入力に対して「ルールブック」で適切な文字を返す
- → 外から見れば中国語を「理解」しているように見える
- → しかし部屋には何の「理解」も「意識」もない
- ---
- LLMは「中国語の部屋」なのか？


---

<!-- _class: lead -->
# LLMは意識を持つか：現時点での考察


---

# 2023年：Googleエンジニアの主張と反響

- 2022年：Google エンジニア Blake Lemoine が
- 「LaMDAは感情を持つ」と主張しGoogleを解雇
- ---
- **科学者の一般的な見解：**
- - LLMは確率的に次のトークンを予測するモデル
- - 「感じているように見える」テキストを生成するが、感じてはいない
- - 意識の物理的基盤（統合情報理論・グローバルワークスペース理論）を満たさない
- ---
- **反論：** しかし我々は他人の意識も直接観測できない
- → 意識の有無を**外部から証明する方法がない**


---

# まとめ：答えのない問いと向き合う

- ✅ **ハードプロブレムは未解決** — 物質がなぜ体験を生むか不明
- ✅ **チューリングテストは意識の証明にならない** — 中国語の部屋
- ✅ **哲学的ゾンビは論理的に可能** — 機能的同一性≠意識の同一性
- ✅ **LLMの意識は現時点で否定も肯定もできない**
- 
- 「問いを正確に立てることが、誤った答えへの最初の防御だ」

